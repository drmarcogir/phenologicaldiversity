{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load required modules\n",
    "import ee\n",
    "ee.Initialize()\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load leaflet interactive map\n",
    "import geemap\n",
    "Map = geemap.Map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prova vecchie metriche (Percentiles) - Esporta alla risoluzione di 500m su assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----- Required functions\n",
    "# add NDVI to data\n",
    "def addNDVI(image):\n",
    "    image = image.updateMask(MakMarco.eq(1))\n",
    "    return image.addBands(image.normalizedDifference(['sur_refl_b02','sur_refl_b01']).rename('NDVI')).float()\n",
    "\n",
    "# function for extracting quality bits\n",
    "def getQABits(image, start, end, mascara):\n",
    "    # Compute the bits we need to extract.\n",
    "    pattern = 0\n",
    "    for i in range(start,end+1):\n",
    "        pattern += 2**i\n",
    "    # Return a single band image of the extracted QA bits, giving the     band a new name.\n",
    "    return image.select([0], [mascara]).bitwiseAnd(pattern).rightShift(start)\n",
    "\n",
    "# mask out low quality pixels (based on flags)\n",
    "def maskPixels(image0):\n",
    "    #Select the QA band\n",
    "    QA = image0.select('state_1km')\n",
    "    # Get the land_water_flag bits\n",
    "    landWaterFlag = getQABits(QA, 3, 5, 'land_water_flag')\n",
    "    #Get the cloud_state bits and find cloudy areas.\n",
    "    cloud = getQABits(QA, 0, 1, 'cloud_state').expression(\"b(0) == 1 || b(0) == 2\")\n",
    "    # Get the cloud_shadow bit\n",
    "    cloudShadows = getQABits(QA, 2, 2, 'cloud_shadow')\n",
    "    # Get the Pixel is adjacent to cloud bit\n",
    "    cloudAdjacent = getQABits(QA, 13, 13, 'cloud_adj')\n",
    "    # Get the internal cloud flag\n",
    "    cloud2 = getQABits(QA, 10, 10, 'cloud_internal')\n",
    "    # Get the internal fire flag\n",
    "    fire = getQABits(QA, 11, 11, 'fire_internal')\n",
    "    # Get the MOD35 snow/ice flag\n",
    "    snow1 = getQABits(QA, 12, 12, 'snow_MOD35')\n",
    "    # Get the internal snow flag\n",
    "    snow2 = getQABits(QA, 15, 15, 'snow_internal')\n",
    "    # create mask\n",
    "    mask = landWaterFlag.eq(1).And(cloud.Not()).And(cloudShadows.Not()).And(cloudAdjacent.Not()).And(cloud2.Not()).And(fire.Not()).And(snow1.Not()).And(snow2.Not())\n",
    "    return image0.updateMask(mask) \n",
    "            \n",
    "\n",
    "# utility function for temporal smoothing\n",
    "def smooth_func(image):\n",
    "    collection = ee.ImageCollection.fromImages(image.get('images'))\n",
    "    return ee.Image(image).addBands(collection.mean().rename('mean'))\n",
    "\n",
    "# masked smoothed dataset\n",
    "def mask_smt(image):\n",
    "    img = image.select('NDVI')\n",
    "    img.updateMask(img.gt(0))\n",
    "    return image.addBands(img)\n",
    "\n",
    "# masked smoothed dataset\n",
    "def unmask_img(image):\n",
    "    return image.unmask()\n",
    "\n",
    "# function for accumulating NDVI\n",
    "def accumulate(image,list):\n",
    "    # Get the latest cumulative NDVI of the list with\n",
    "    # get(-1).  Since the type of the list argument to the function is unknown,\n",
    "    # it needs to be cast to a List.  Since the return type of get() is unknown,\n",
    "    # cast it to Image.\n",
    "    previous = ee.Image(ee.List(list).get(-1)).toFloat()\n",
    "    # Add the current anomaly to make a new cumulative NDVI image and Propagate metadata to the new image.\n",
    "    added = image.toFloat().add(previous).toFloat().set('system:time_start', image.get('system:time_start'))\n",
    "    return ee.List(list).add(added)\n",
    "\n",
    "\n",
    "# add day of the year\n",
    "def addDOY(image):\n",
    "    return image.addBands(ee.Image.constant(ee.Number.parse(image.date().format('D'))).rename('DOY').float())\n",
    "\n",
    "# calculate 50th percentile\n",
    "def perc_50(img):\n",
    "    # subtract the 50th percentile from each image, square to remove negative, append summed difference to image \n",
    "    dif = ee.Image(img).select(['mean']).subtract(Sum_NDVI.divide(2)).pow(ee.Image.constant(2)).multiply(-1).rename('quality')\n",
    "    return img.addBands(dif)\n",
    "\n",
    "# calculate 25th percentile\n",
    "def perc_25(img):\n",
    "    dif = ee.Image(img).select(['mean']).subtract(Sum_NDVI.divide(4)).pow(ee.Image.constant(2)).multiply(-1).rename('quality')\n",
    "    return img.addBands(dif)\n",
    "\n",
    "# calculate 75th percentile\n",
    "def perc_75(img):\n",
    "    dif = ee.Image(img).select(['mean']).subtract(Sum_NDVI.divide(4).multiply(3)).pow(ee.Image.constant(2)).multiply(-1).rename('quality')\n",
    "    return img.addBands(dif)\n",
    "\n",
    "# rename band\n",
    "def rename_d(image):\n",
    "    return Final_output_.select([b]).rename('value')\n",
    "\n",
    "# smoothed mask for NDVI max\n",
    "def mask_maxndvi(image):\n",
    "    image = image.updateMask(count_valid.gte(30))\n",
    "    return image.updateMask(image.select('NDVI').gt(0))\n",
    "\n",
    "# rename ndvi for max ndvi dataset\n",
    "def rename_maxndvi(b):\n",
    "    return Final_output_.select([b]).rename('value')\n",
    "\n",
    "# filter pixels greater than 10 %\n",
    "def ndvi_filter10(image):\n",
    "    return image.updateMask(image.gte(MaxNDVI_10))\n",
    "# clipping function\n",
    "def clip_area(image):\n",
    "    res = image.clip(barea)\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- load datasets\n",
    "# load MODIS data (daily 500m resolution)\n",
    "collection = ee.ImageCollection('MODIS/006/MOD09GA').filterDate('2001-01-01', '2019-12-31').filterBounds(barea.geometry())\n",
    "# mask of pixels that were unchanged (until 2015)\n",
    "MakMarco = ee.Image(\"users/marcogirardello/phenoutils/mask_unchanged_500m\")\n",
    "# Region for cropping final datasets\n",
    "Rectangle1 = ee.Geometry.Polygon(\n",
    "        [[[-178.2918491139962, 73.88593845172474],\n",
    "          [-178.2918491139962, -61.42493117272831],\n",
    "          [179.98940088600375, -61.42493117272831],\n",
    "          [179.98940088600375, 73.88593845172474]]], None, False)\n",
    "# grid for export to assets\n",
    "worldgrid = ee.FeatureCollection('users/marcogirardello/phenoutils/grid_export_phenology')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set dates\n",
    "start_date = ee.Date.fromYMD(2001, 1, 1)\n",
    "end_date   = ee.Date.fromYMD(2019, 12, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# broad areas\n",
    "export_grid =ee.FeatureCollection('users/marcogirardello/phenoutils/grid_export_phenology')\n",
    "onesquare = export_grid.filterMetadata('polyID','equals',28)\n",
    "#barea = onesquare.geometry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask pixels\n",
    "MOD09masked = collection.filterDate(start_date, end_date).map(maskPixels)\n",
    "# add NDVI band\n",
    "MOD09ndvi = MOD09masked.map(addNDVI).select('NDVI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Image' object has no attribute 'median'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-88c6883ce8e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#### FILTERING!!! TEST\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mMOD09ndvi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMOD09ndvi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Image' object has no attribute 'median'"
     ]
    }
   ],
   "source": [
    "#### FILTERING!!! TEST\n",
    "MOD09ndvi = MOD09ndvi.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prova anni 2001 e 2019 a 500m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through years\n",
    "years = list([2001,2019])\n",
    "# list of polygons\n",
    "polygons = list(range(1, 42+1))\n",
    "\n",
    "for year in years:\n",
    "    #print(year)\n",
    "    # start and end date for a given year\n",
    "    start_date = ee.Date.fromYMD(year,1,1)\n",
    "    end_date = ee.Date.fromYMD(year,12,31)\n",
    "    # filter dataset for a given year\n",
    "    MOD09ndviY = MOD09ndvi.filterDate(start_date, end_date)\n",
    "    # filter according to 10% rule\n",
    "    MaxNDVI_10 = MOD09ndviY.max().divide(10)\n",
    "    MOD09ndviY = MOD09ndviY.map(ndvi_filter10)\n",
    "    # value for the temporal smoothing bandwidth (21 days)\n",
    "    bw = 21\n",
    "    # This field contains UNIX time in milliseconds\n",
    "    timeField = 'system:time_start'\n",
    "    # sort collection by date\n",
    "    filteredMODIS = MOD09ndviY.sort('system:time_start')\n",
    "    # Smoothing\n",
    "    join = ee.Join.saveAll(matchesKey = 'images')\n",
    "    diffFilter = ee.Filter.maxDifference(difference =1000 * 60 * 60 * 24 * bw, \n",
    "                                     leftField = timeField,rightField = timeField)\n",
    "    threeNeighborJoin = join.apply(primary = filteredMODIS,secondary = filteredMODIS,condition = diffFilter)\n",
    "    # get smoothed collection\n",
    "    smoothed = ee.ImageCollection(threeNeighborJoin.map(smooth_func))\n",
    "    # mask smoothed dataset\n",
    "    smoothed_masked = smoothed.map(mask_smt)\n",
    "    # count valid images\n",
    "    count_valid = smoothed_masked.select('NDVI').count()\n",
    "    # unmask smoothed dataset\n",
    "    smoothed = smoothed.map(unmask_img)\n",
    "    # select mean band\n",
    "    smoothed = smoothed.select('mean')\n",
    "    # Define reference conditions from the first  year of data.\n",
    "    # Sort chronologically in descending order.\n",
    "    reference = smoothed.sort('system:time_start', True)\n",
    "    # Get the timestamp from the most recent image in the reference collection.\n",
    "    time0 = reference.first().get('system:time_start')\n",
    "    # Use imageCollection.iterate() to make a collection of cumulative NDVI over time.\n",
    "    # Rename the first band 'NDVI'.\n",
    "    first = ee.List([ee.Image(0).set('system:time_start', time0).select([0], ['mean']).toFloat()])\n",
    "    # cumulate NDVI\n",
    "    cumulative = ee.ImageCollection(ee.List(reference.iterate(accumulate, first)))\n",
    "    # normalise\n",
    "    # add day of the year\n",
    "    cumulativeDOI = cumulative.map(addDOY)\n",
    "    # sum NDVI\n",
    "    Sum_NDVI = smoothed.sum()\n",
    "    #--- compute 50th percentile\n",
    "    difFrom50 = cumulativeDOI.map(perc_50)\n",
    "    DOY50 = difFrom50.qualityMosaic('quality')\n",
    "    DOY50 = DOY50.updateMask(DOY50.select('mean').gt(0))\n",
    "    DOY50 = DOY50.updateMask(count_valid.gte(30))\n",
    "    DOY50 = DOY50.select('DOY')\n",
    "    for polygon in polygons:\n",
    "        print('DOY50 Year '+str(year)+' Polygon number '+str(polygon))\n",
    "        # subset polygon\n",
    "        tmp_poly = worldgrid.filterMetadata('polyID', 'equals', polygon).first().geometry()\n",
    "        # assetname\n",
    "        assetname = 'DOY50_'+str(year)+'_'+str(polygon)\n",
    "        # export tile\n",
    "        task = ee.batch.Export.image.toAsset(image=DOY50,description=assetname,assetId = 'users/marcogirardello/phenology/'+assetname,\n",
    "                                     scale=463.3127165275,crs = 'EPSG:4326',maxPixels = 1e13,region = tmp_poly)\n",
    "        task.start()\n",
    "    #--- compute 25th percentile\n",
    "    difFrom25 = cumulativeDOI.map(perc_25)\n",
    "    DOY25 = difFrom25.qualityMosaic('quality')\n",
    "    DOY25 = DOY25.updateMask(DOY25.select('mean').gt(0))\n",
    "    DOY25 = DOY25.updateMask(count_valid.gte(30))\n",
    "    DOY25 = DOY25.select('DOY')\n",
    "    for polygon in polygons:\n",
    "        print('DOY25 Year '+str(year)+' Polygon number '+str(polygon))\n",
    "        # subset polygon\n",
    "        tmp_poly = worldgrid.filterMetadata('polyID', 'equals', polygon).first().geometry()\n",
    "        # assetname\n",
    "        assetname = 'DOY25_'+str(year)+'_'+str(polygon)\n",
    "            # export tile\n",
    "        task = ee.batch.Export.image.toAsset(image=DOY25,description=assetname,assetId = 'users/marcogirardello/phenology'+assetname,\n",
    "                                     scale=463.3127165275,crs = 'EPSG:4326',maxPixels = 1e13,region = tmp_poly)\n",
    "        task.start()\n",
    "    \n",
    "    #--- compute 75th percentile\n",
    "    difFrom75 = cumulativeDOI.map(perc_75)\n",
    "    DOY75 = difFrom75.qualityMosaic('quality')\n",
    "    DOY75 = DOY75.updateMask(DOY75.select('mean').gt(0))\n",
    "    DOY75 = DOY75.updateMask(count_valid.gte(30))\n",
    "    DOY75 = DOY75.select('DOY')\n",
    "    for polygon in polygons:\n",
    "        print('DOY75 Year '+str(year)+' Polygon number '+str(polygon))\n",
    "        # subset polygon\n",
    "        tmp_poly = worldgrid.filterMetadata('polyID', 'equals', polygon).first().geometry()\n",
    "        # assetname\n",
    "        assetname = 'DOY75_'+str(year)+'_'+str(polygon)\n",
    "            # export tile\n",
    "        task = ee.batch.Export.image.toAsset(image=DOY75,description=assetname,assetId = 'users/marcogirardello/phenology'+assetname,\n",
    "                                     scale=463.3127165275,crs = 'EPSG:4326',maxPixels = 1e13,region = tmp_poly)\n",
    "        task.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ee.batch.Task.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(year)\n",
    "# start and end date for a given year\n",
    "start_date = ee.Date.fromYMD(year,1,1)\n",
    "end_date = ee.Date.fromYMD(year,12,31)\n",
    "# filter dataset for a given year\n",
    "MOD09ndviY = MOD09ndvi.filterDate(start_date, end_date)\n",
    "# filter according to 10% rule\n",
    "MaxNDVI_10 = MOD09ndviY.max().divide(10)\n",
    "MOD09ndviY = MOD09ndviY.map(ndvi_filter10)\n",
    "\n",
    "# value for the temporal smoothing bandwidth (21 days)\n",
    "bw = 21\n",
    "# This field contains UNIX time in milliseconds\n",
    "timeField = 'system:time_start'\n",
    "# sort collection by date\n",
    "filteredMODIS = MOD09ndviY.sort('system:time_start')\n",
    "# Smoothing\n",
    "join = ee.Join.saveAll(matchesKey = 'images')\n",
    "diffFilter = ee.Filter.maxDifference(difference =1000 * 60 * 60 * 24 * bw, \n",
    " leftField = timeField,rightField = timeField)\n",
    "threeNeighborJoin = join.apply(primary = filteredMODIS,secondary = filteredMODIS,condition = diffFilter)\n",
    "# get smoothed collection\n",
    "smoothed = ee.ImageCollection(threeNeighborJoin.map(smooth_func))\n",
    "# mask smoothed dataset\n",
    "smoothed_masked = smoothed.map(mask_smt)\n",
    "# count valid images\n",
    "count_valid = smoothed_masked.select('NDVI').count()\n",
    "# unmask smoothed dataset\n",
    "smoothed = smoothed.map(unmask_img)\n",
    "# select mean band\n",
    "smoothed = smoothed.select('mean')\n",
    "# Define reference conditions from the first  year of data.\n",
    "# Sort chronologically in descending order.\n",
    "reference = smoothed.sort('system:time_start', True)\n",
    "# Get the timestamp from the most recent image in the reference collection.\n",
    "time0 = reference.first().get('system:time_start')\n",
    "# Use imageCollection.iterate() to make a collection of cumulative NDVI over time.\n",
    "# Rename the first band 'NDVI'.\n",
    "first = ee.List([ee.Image(0).set('system:time_start', time0).select([0], ['mean']).toFloat()])\n",
    "# cumulate NDVI\n",
    "cumulative = ee.ImageCollection(ee.List(reference.iterate(accumulate, first)))\n",
    "# normalise\n",
    "# add day of the year\n",
    "cumulativeDOI = cumulative.map(addDOY)\n",
    "# sum NDVI\n",
    "Sum_NDVI = smoothed.sum()\n",
    "#--- compute 50th percentile\n",
    "difFrom50 = cumulativeDOI.map(perc_50)\n",
    "DOY50 = difFrom50.qualityMosaic('quality')\n",
    "DOY50 = DOY50.updateMask(DOY50.select('mean').gt(0))\n",
    "DOY50 = DOY50.updateMask(count_valid.gte(30))\n",
    "DOY50 = DOY50.select('DOY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#barea = ee.FeatureCollection(Map.draw_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map.addLayer(MOD09ndvi,'','MOD09ndvi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map.addLayer(barea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a2419b1ae640ee8bc6d9892467bd41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[40, -100], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoom_out_t…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh = difFrom50.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map.addLayer(onesquare,'','poly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map.addLayer(hh,'','CUR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = ee.FeatureCollection(Map.draw_features)\n",
    "Map.addLayer(poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOY50 = MOD09ndvi.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  reproject image in latlon (same input 5 km x 5km inputgrid) \n",
    "#DOY50 = DOY50.reproject(crs='EPSG:4326',scale= 463.3127165275) \n",
    "# 5 km x 5 km grid\n",
    "mask_5km = ee.Image('users/marcogirardello/pheno_grid').int()\n",
    "onesquare = export_grid.filterMetadata('polyID','equals',28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert feature collection into feature collection with no geometry (easier to save)\n",
    "def convert(feature):\n",
    "    res = ee.Feature(None,feature.toDictionary())\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert 5km grid into vectors (pixels become polygons!)\n",
    "vectors = mask_5km.reduceToVectors(crs = mask_5km.projection(),geometry = onesquare,scale =100,\n",
    "                                           geometryType = 'polygon',eightConnected = False, labelProperty ='zone',\n",
    "                                           reducer= ee.Reducer.countEvery(),maxPixels= 1e13) \n",
    "tmpimage2 = DOY50.clip(onesquare)\n",
    "# calculate statistics of interest (standard deviation)\n",
    "stats = tmpimage2.reduceRegions(collection = vectors,reducer = ee.Reducer.stdDev(),\n",
    "                                          scale = 463.3127165275)\n",
    "# convert to dictionary (set geometry to null!)\n",
    "stats1 = stats.map(convert)\n",
    "task= ee.batch.Export.table.toDrive(collection = stats1,description ='currus_clippedv15cur',folder=\"phenology_csv\",\n",
    "                                        fileFormat='CSV')\n",
    "#task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map.addLayer(onesquare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b229bd7af83c47a5b397356d8ae92ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[-7.710991655433217, 47.81250000000001], controls=(ZoomControl(options=['position', 'zoom_in_text',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# polygon numbers for broad areas\n",
    "polygons = list(range(1, 2+1))\n",
    "for polygon in polygons:\n",
    "    print(polygon)\n",
    "    # subset one broad area\n",
    "    onesquare = export_grid.filterMetadata('polyID','equals',polygon)\n",
    "    # convert 5km grid into vectors (pixels become polygons!)\n",
    "    vectors = mask_5km.reduceToVectors(crs = mask_5km.projection(),geometry = onesquare,scale =100,\n",
    "                                           geometryType = 'polygon',eightConnected = False, labelProperty ='zone',\n",
    "                                           reducer= ee.Reducer.countEvery(),maxPixels= 1e13)\n",
    "    # calculate statistics of interest (standard deviation)\n",
    "    stats = tmpimage1.reduceRegions(collection = vectors,reducer = ee.Reducer.stdDev(),\n",
    "                                          scale = 463.3127165275)\n",
    "    # convert to dictionary (set geometry to null!)\n",
    "    stats1 = stats.map(convert)\n",
    "    # filename\n",
    "    filename = 'DOY50_sd_v6_'+str(polygon)\n",
    "    #Export the FeatureCollection.\n",
    "    task= ee.batch.Export.table.toDrive(collection = stats1,description =filename,folder=\"phenology_csv\",\n",
    "                                        fileFormat='CSV')\n",
    "    task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
