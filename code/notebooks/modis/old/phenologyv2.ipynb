{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create phenology datasets and export them to google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load required modules\n",
    "import ee\n",
    "ee.Initialize()\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load leaflet interactive map\n",
    "import geemap\n",
    "Map = geemap.Map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCD12Q2 v006 phenology product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for extracting quality bits\n",
    "def getQABits(image, start, end, mascara):\n",
    "    # Compute the bits we need to extract.\n",
    "    pattern = 0\n",
    "    for i in range(start,end+1):\n",
    "        pattern += 2**i\n",
    "    # Return a single band image of the extracted QA bits, giving the     band a new name.\n",
    "    return image.select([0], [mascara]).bitwiseAnd(pattern).rightShift(start)\n",
    "    \n",
    "# function for filtering image based on quality bits\n",
    "def mask_pixelsall(bstart,bend):\n",
    "    def maskPixels(image0):\n",
    "        tmp = image0.select('QA_Detailed_1')\n",
    "        quality = getQABits(tmp, bstart, bend, 'QA_Detailed_1')\n",
    "        # Create a mask that filters out undesired areas\n",
    "        mask = quality.eq(0).Or(quality.eq(1)).Or(quality.eq(2))\n",
    "        return image0.updateMask(mask) \n",
    "    return(maskPixels)\n",
    "\n",
    "# function for masking areas where there have not land use changes. This layer was created using the ESA cci map\n",
    "def mask_image(image):\n",
    "    image = image.updateMask(MakMarco.eq(1))\n",
    "    return image\n",
    "\n",
    "# convert feature collection into feature collection with no geometry (easier to save)\n",
    "def convert(feature):\n",
    "    res = ee.Feature(None,feature.toDictionary())\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- load datasets\n",
    "# load MODIS phenology product\n",
    "modis_phenoprod = ee.ImageCollection('MODIS/006/MCD12Q2')\n",
    "# load mask of unchanged forest pixels\n",
    "MakMarco = ee.Image(\"users/marcogirardello/phenoutils/mask_unchanged_500m\")\n",
    "# 5 km x 5 km grid\n",
    "mask_5km = ee.Image('users/marcogirardello/phenoutils/pheno_grid').int()\n",
    "# broad areas\n",
    "export_grid =ee.FeatureCollection('users/marcogirardello/phenoutils/grid_export_phenology')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n"
     ]
    }
   ],
   "source": [
    "# polygon numbers for broad areas\n",
    "polygons = list(range(1, 42+1))\n",
    "\n",
    "# list of years\n",
    "years = list(range(2001, 2016+1))\n",
    "\n",
    "for year in years:\n",
    "    print(year)\n",
    "    # filter for year of interest\n",
    "    pheno_tmp = modis_phenoprod.filter(ee.Filter.date(str(year)+'-01-01', str(year+1)+'-01-01'))\n",
    "    # ------- Greenup\n",
    "    GUP = pheno_tmp.select(['Greenup_1','QA_Detailed_1'])\n",
    "    # only take pixels above a certain threshold level\n",
    "    GUP1 = GUP.map(mask_pixelsall(bstart=0,bend=1)).select('Greenup_1').first()\n",
    "    # filter using mask where pixels have been stable\n",
    "    GUP2 = GUP1.updateMask(MakMarco.eq(1))\n",
    "    # reproject latlon\n",
    "    GUP3 = GUP2.reproject(crs='EPSG:4326',scale= 463.3127165275)\n",
    "    # export as CSV file\n",
    "    for polygon in polygons:\n",
    "        #print(polygon)\n",
    "        # subset one broad area\n",
    "        onesquare = export_grid.filterMetadata('polyID','equals',polygon)\n",
    "        # convert 5km grid into vectors (pixels become polygons!)\n",
    "        vectors = mask_5km.reduceToVectors(crs = mask_5km.projection(),geometry = onesquare,scale =100,\n",
    "                                           geometryType = 'polygon',eightConnected = False, labelProperty ='zone',\n",
    "                                           reducer= ee.Reducer.countEvery(),maxPixels= 1e13)\n",
    "        # calculate statistics of interest (standard deviation)\n",
    "        stats = GUP3.reduceRegions(collection = vectors,reducer = ee.Reducer.stdDev(),\n",
    "                                          scale = 463.3127165275)\n",
    "        # convert to dictionary (set geometry to null!)\n",
    "        stats1 = stats.map(convert)\n",
    "        # filename \n",
    "        filename = 'GUP_sd_'+str(year)+'_'+str(polygon)\n",
    "        #Export the FeatureCollection.\n",
    "        task= ee.batch.Export.table.toDrive(collection = stats1,description =filename,folder=\"phenology_csv\",\n",
    "                                        fileFormat='CSV')\n",
    "        task.start()\n",
    "        \n",
    "    # ------- Peak\n",
    "    # subset Peak for given year\n",
    "    Peak = pheno_tmp.select(['Peak_1','QA_Detailed_1'])\n",
    "    # only take pixels above a certain threshold level\n",
    "    Peak1 = Peak.map(mask_pixelsall(bstart=6,bend=7)).select('Peak_1').first()\n",
    "    # filter using mask where pixels have been stable\n",
    "    Peak2 = Peak1.updateMask(MakMarco.eq(1))\n",
    "    # reproject latlon\n",
    "    Peak3 = Peak2.reproject(crs='EPSG:4326',scale= 463.3127165275)\n",
    "    # export as CSV file\n",
    "    for polygon in polygons:\n",
    "        #print(polygon)\n",
    "        # subset one broad area\n",
    "        onesquare = export_grid.filterMetadata('polyID','equals',polygon)\n",
    "        # convert 5km grid into vectors (pixels become polygons!)\n",
    "        vectors = mask_5km.reduceToVectors(crs = mask_5km.projection(),geometry = onesquare,scale =100,\n",
    "                                           geometryType = 'polygon',eightConnected = False, labelProperty ='zone',\n",
    "                                           reducer= ee.Reducer.countEvery(),maxPixels= 1e13)\n",
    "        # calculate statistics of interest (standard deviation)\n",
    "        stats = Peak3.reduceRegions(collection = vectors,reducer = ee.Reducer.stdDev(),\n",
    "                                          scale = 463.3127165275)\n",
    "        # convert to dictionary (set geometry to null!)\n",
    "        stats1 = stats.map(convert)\n",
    "        # filename \n",
    "        filename = 'Peak_sd_'+str(year)+'_'+str(polygon)\n",
    "        #Export the FeatureCollection.\n",
    "        task= ee.batch.Export.table.toDrive(collection = stats1,description =filename,folder=\"phenology_csv\",\n",
    "                                        fileFormat='CSV')\n",
    "        task.start()\n",
    "        \n",
    "    # ------- Dormancy\n",
    "    Dormancy = pheno_tmp.select(['Dormancy_1','QA_Detailed_1'])\n",
    "    # only take pixels above a certain threshold level\n",
    "    Dormancy1 = Dormancy.map(mask_pixelsall(bstart=12,bend=13)).select('Dormancy_1').first()\n",
    "    # filter using mask where pixels have been stable\n",
    "    Dormancy2 = Dormancy1.updateMask(MakMarco.eq(1))\n",
    "    # calculate standard deviation\n",
    "    Dormancy3 = Dormancy2.reproject(crs='EPSG:4326',scale= 463.3127165275)\n",
    "    # export as CSV file\n",
    "    for polygon in polygons:\n",
    "        #print(polygon)\n",
    "        # subset one broad area\n",
    "        onesquare = export_grid.filterMetadata('polyID','equals',polygon)\n",
    "        # convert 5km grid into vectors (pixels become polygons!)\n",
    "        vectors = mask_5km.reduceToVectors(crs = mask_5km.projection(),geometry = onesquare,scale =100,\n",
    "                                           geometryType = 'polygon',eightConnected = False, labelProperty ='zone',\n",
    "                                           reducer= ee.Reducer.countEvery(),maxPixels= 1e13)\n",
    "        # calculate statistics of interest (standard deviation)\n",
    "        stats = Dormancy3.reduceRegions(collection = vectors,reducer = ee.Reducer.stdDev(),\n",
    "                                          scale = 463.3127165275)\n",
    "        # convert to dictionary (set geometry to null!)\n",
    "        stats1 = stats.map(convert)\n",
    "        # filename \n",
    "        filename = 'Dormancy_sd_'+str(year)+'_'+str(polygon)\n",
    "        #Export the FeatureCollection.\n",
    "        task= ee.batch.Export.table.toDrive(collection = stats1,description =filename,folder=\"phenology_csv\",\n",
    "                                        fileFormat='CSV')\n",
    "        task.start()\n",
    "    # ------- Season length\n",
    "    season_length = Dormancy2.subtract(GUP2)\n",
    "    season_length1 = season_length.reproject(crs='EPSG:4326',scale= 463.3127165275)\n",
    "    # export as CSV file\n",
    "    for polygon in polygons:\n",
    "        #print(polygon)\n",
    "        # subset one broad area\n",
    "        onesquare = export_grid.filterMetadata('polyID','equals',polygon)\n",
    "        # convert 5km grid into vectors (pixels become polygons!)\n",
    "        vectors = mask_5km.reduceToVectors(crs = mask_5km.projection(),geometry = onesquare,scale =100,\n",
    "                                           geometryType = 'polygon',eightConnected = False, labelProperty ='zone',\n",
    "                                           reducer= ee.Reducer.countEvery(),maxPixels= 1e13)\n",
    "        # calculate statistics of interest (standard deviation)\n",
    "        stats = season_length1.reduceRegions(collection = vectors,reducer = ee.Reducer.stdDev(),\n",
    "                                          scale = 463.3127165275)\n",
    "        # convert to dictionary (set geometry to null!)\n",
    "        stats1 = stats.map(convert)\n",
    "        # filename \n",
    "        filename = 'SL_sd_'+str(year)+'_'+str(polygon)\n",
    "        #Export the FeatureCollection.\n",
    "        task= ee.batch.Export.table.toDrive(collection = stats1,description =filename,folder=\"phenology_csv\",\n",
    "                                        fileFormat='CSV')\n",
    "        task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
