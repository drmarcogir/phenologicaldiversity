{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guido's code https://code.earthengine.google.com/658483bbe548918a14000301e4640c52 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "ee.Initialize()\n",
    "import geemap\n",
    "Map = geemap.Map()\n",
    "import time\n",
    "import datetime\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add dn for product aggregated into 8 days\n",
    "def add_dn_date(img,beginDate=None,n=None,IncludeYear=False):\n",
    "    if beginDate is None:\n",
    "        beginDate = img.get('system:time_start')\n",
    "    else:\n",
    "        beginDate = beginDate\n",
    "    if IncludeYear is False:\n",
    "        IncludeYear = True\n",
    "    if n is None:\n",
    "        n = 8\n",
    "    beginDate = ee.Date(beginDate)\n",
    "    year  = beginDate.get('year')\n",
    "    month = beginDate.get('month')\n",
    "    diff  = beginDate.difference(ee.Date.fromYMD(year, 1, 1), 'day').add(1)\n",
    "    dn    = diff.subtract(1).divide(n).floor().add(1).int()\n",
    "    yearstr  = year.format('%d') \n",
    "    dn = dn.format('%02d')\n",
    "    return ee.Image(img).set('system:time_start', beginDate.millis()).set('date', beginDate.format('yyyy-MM-dd')).set('Year', yearstr).set('Month',beginDate.format('MM')).set('YearMonth', beginDate.format('YYYY-MM')).set('dn', dn)\n",
    "\n",
    "# wrapper function for add_dn_date\n",
    "def add_dn_date_all(Year,days):\n",
    "    def wrapper(image0):\n",
    "        tmp = add_dn_date(img = image0,IncludeYear=Year,n = days)\n",
    "        return tmp\n",
    "    return (wrapper)\n",
    "\n",
    "# add NDVI to data\n",
    "def addNDVI(image):\n",
    "    #image = image.updateMask(MakMarco.eq(1))\n",
    "    return image.addBands(image.normalizedDifference(['sur_refl_b02','sur_refl_b01']).rename('NDVI')).float()\n",
    "\n",
    "# function for extracting quality bits\n",
    "def getQABits(image, start, end, mascara):\n",
    "    # Compute the bits we need to extract.\n",
    "    pattern = 0\n",
    "    for i in range(start,end+1):\n",
    "        pattern += 2**i\n",
    "    # Return a single band image of the extracted QA bits, giving the     band a new name.\n",
    "    return image.select([0], [mascara]).bitwiseAnd(pattern).rightShift(start)\n",
    "\n",
    "# mask out low quality pixels (based on flags)\n",
    "def maskPixels(image0):\n",
    "    #Select the QA band\n",
    "    QA = image0.select('StateQA')\n",
    "    # Get the land_water_flag bits\n",
    "    landWaterFlag = getQABits(QA, 3, 5, 'land_water_flag')\n",
    "    #Get the cloud_state bits and find cloudy areas.\n",
    "    cloud = getQABits(QA, 0, 1, 'cloud_state').expression(\"b(0) == 1 || b(0) == 2\")\n",
    "    # Get the cloud_shadow bit\n",
    "    cloudShadows = getQABits(QA, 2, 2, 'cloud_shadow')\n",
    "    # Get the Pixel is adjacent to cloud bit\n",
    "    cloudAdjacent = getQABits(QA, 13, 13, 'cloud_adj')\n",
    "    # Get the internal cloud flag\n",
    "    cloud2 = getQABits(QA, 10, 10, 'cloud_internal')\n",
    "    # Get the internal fire flag\n",
    "    fire = getQABits(QA, 11, 11, 'fire_internal')\n",
    "    # Get the MOD35 snow/ice flag\n",
    "    snow1 = getQABits(QA, 12, 12, 'snow_MOD35')\n",
    "    # Get the internal snow flag\n",
    "    snow2 = getQABits(QA, 15, 15, 'snow_internal')\n",
    "    # create mask\n",
    "    mask = landWaterFlag.eq(1).And(cloud.Not()).And(cloudShadows.Not()).And(cloudAdjacent.Not()).And(cloud2.Not()).And(fire.Not()).And(snow1.Not()).And(snow2.Not())\n",
    "    return image0.updateMask(mask) \n",
    "\n",
    "def smooth_func(image): \n",
    "    collection = ee.ImageCollection.fromImages(image.get('images'))\n",
    "    return ee.Image(image).addBands(collection.mean().rename(['mean']))\n",
    "\n",
    "def clim5y(month):\n",
    "    month = ee.String(month)\n",
    "    seqNDVI = MOD09ndviY.filterMetadata('dn', 'equals',month)\n",
    "    return seqNDVI.median().copyProperties(seqNDVI.first(), ['system:time_start','system:time_end','dn'])\n",
    "\n",
    "# filter smoothed map\n",
    "def filt_smoothed(image):\n",
    "    image = image.select('NDVI')\n",
    "    image = image.unmask()\n",
    "    image = image.where(image.eq(0),MinNDVI)\n",
    "    return image.updateMask(count_valid.gte(20))\n",
    "\n",
    "# function for accumulating NDVI\n",
    "def accumulate(image,list):\n",
    "    # Get the latest cumulative NDVI of the list with\n",
    "    # get(-1).  Since the type of the list argument to the function is unknown,\n",
    "    # it needs to be cast to a List.  Since the return type of get() is unknown,\n",
    "    # cast it to Image.\n",
    "    previous = ee.Image(ee.List(list).get(-1)).toFloat()\n",
    "    # Add the current anomaly to make a new cumulative NDVI image and Propagate metadata to the new image.\n",
    "    added = image.toFloat().add(previous).toFloat().set('system:time_start', image.get('system:time_start'))\n",
    "    return ee.List(list).add(added)\n",
    "\n",
    "# cumulative normalized\n",
    "def cum_dividelast(image):\n",
    "    return image.divide(last)\n",
    "\n",
    "# calculate deviations\n",
    "def deviations_calc(image):\n",
    "    tmp = image.select('NDVI').reproject(crs = 'SR-ORG:6974',scale = 463.3127165275).reduceNeighborhood(reducer='stdDev',kernel= ee.Kernel.square(6, 'pixels'),skipMasked =True)\n",
    "    return tmp\n",
    "\n",
    "\n",
    "def addTimeBand(img):\n",
    "    ## make sure mask is consistent ##\n",
    "    mask = img.mask()\n",
    "    time = img.metadata('system:time_start').rename(\"time\").mask(mask)\n",
    "    return img.addBands(time)\n",
    "\n",
    "\n",
    "def replace_mask(img, newimg, nodata):\n",
    "    if frame is None:\n",
    "        nodata = 8\n",
    "    # var con = img.mask();\n",
    "    # var res = img., NODATA\n",
    "    mask = img.mask()\n",
    "    # The only nsolution is unmask & updatemask */\n",
    "    img = img.unmask(nodata)\n",
    "    img = img.where(mask.Not(), newimg)\n",
    "    img = img.updateMask(img.neq(nodata))\n",
    "    return img\n",
    "    \n",
    "def linearInterp(imgcol,frame = None,nodata = None):\n",
    "    if frame is None:\n",
    "        frame = 32\n",
    "    if nodata is None:\n",
    "        nodata = 0\n",
    "    timestart   = 'system:time_start'\n",
    "    imgcol = imgcol.map(addTimeBand)\n",
    "    \n",
    "    # We'll look for all images up to 32 days away from the current image.\n",
    "    maxDiff = ee.Filter.maxDifference(frame * (1000*60*60*24), timestart, None, timestart)\n",
    "    \n",
    "    #cond    = {'leftField':timestart, 'rightField':timestart}\n",
    "    # Images after, sorted in descending order (so closest is last).\n",
    "    #var f1 = maxDiff.and(ee.Filter.lessThanOrEquals(time, null, time))\n",
    "    f1 = ee.Filter.And(maxDiff, ee.Filter.lessThanOrEquals(leftField = timestart,rightField = timestart))\n",
    "    c1 = ee.Join.saveAll(matchesKey = 'after', ordering = timestart, ascending = False).apply(imgcol, imgcol, f1)\n",
    "    # Images before, sorted in ascending order (so closest is last).\n",
    "    # var f2 = maxDiff.and(ee.Filter.greaterThanOrEquals(time, null, time))\n",
    "    \n",
    "    f2 = ee.Filter.And(maxDiff, ee.Filter.greaterThanOrEquals(leftField = timestart,rightField = timestart))\n",
    "    c2 = ee.Join.saveAll(matchesKey = 'before', ordering = timestart, ascending = True).apply(c1, imgcol, f2)\n",
    "    \n",
    "    # interpolation \n",
    "    def func_its(img):\n",
    "        img = ee.Image(img)\n",
    "        before = ee.ImageCollection.fromImages(ee.List(img.get('before'))).mosaic()\n",
    "        after  = ee.ImageCollection.fromImages(ee.List(img.get('after'))).mosaic()\n",
    "        img = img.set('before', {}).set('after', {})\n",
    "        \n",
    "        # constrain after or before no NA values, confirm linear Interp having result\n",
    "        before = replace_mask(before, after, nodata)\n",
    "        after  = replace_mask(after , before, nodata)\n",
    "        \n",
    "        # Compute the ratio between the image times.\n",
    "        x1 = before.select('time').double()\n",
    "        x2 = after.select('time').double()\n",
    "        now = ee.Image.constant(img.date().millis()).double()\n",
    "        ratio = now.subtract(x1).divide(x2.subtract(x1))  # this is zero anywhere x1 = x2\n",
    "        \n",
    "        # Compute the interpolated image.\n",
    "        before = before.select(0); #remove time band now\n",
    "        after  = after.select(0)\n",
    "        img    = img.select(0)\n",
    "        interp = after.subtract(before).multiply(ratio).add(before)\n",
    "        qc = img.mask().Not().rename('qc')\n",
    "        interp = replace_mask(img, interp, nodata)\n",
    "        \n",
    "        # Map.addLayer(interp, {}, 'interp')\n",
    "        return interp.addBands(qc).copyProperties(img, img.propertyNames())\n",
    "    interpolated = ee.ImageCollection(c2.map(func_its))\n",
    "    return interpolated\n",
    "\n",
    "# convert feature collection into feature collection with no geometry (easier to save)\n",
    "def convert(feature):\n",
    "    res = ee.Feature(None,feature.toDictionary())\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#geemap.js_snippet_to_py(js_snippet, add_new_cell=True, import_ee=True, import_geemap=True, show_map=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in collections and required images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load collections and required images\n",
    "collection = ee.ImageCollection('MODIS/006/MOD09A1').filterDate('2000-01-01', '2020-12-31')\n",
    "forestmask = ee.Image(\"users/marcogirardello/phenoutils/mask_unchanged_500m\")\n",
    "worldgrid = ee.FeatureCollection('users/marcogirardello/phenoutils/grid_export_phenology1')\n",
    "#smallgrid = ee.FeatureCollection('users/marcogirardello/phenoutils/small5kmit')\n",
    "testarea = ee.Image('users/marcogirardello/phenoutils/NDVI_small')\n",
    "smallgrid = ee.FeatureCollection('users/marcogirardello/phenoutils/grid_export_phenology2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Pre-processing step 1: filtering data by quality flags and calculated NDVI.</span>\n",
    "This include snow, cloud, fire, cloud shadows and the land/water mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end and start date of period of interest\n",
    "start_date = ee.Date.fromYMD(2001, 1, 1)\n",
    "end_date   = ee.Date.fromYMD(2015, 12, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add dn\n",
    "collection = collection.map(add_dn_date_all(Year = False, days = 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask out crap pixels\n",
    "MOD09masked = collection.filterDate(start_date, end_date).map(maskPixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add NDVI as a new band\n",
    "MOD09ndvi = MOD09masked.map(addNDVI).select('NDVI')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Main calculations</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of seasons\n",
    "tmpseas = [\"%02d\" % x for x in list(range(1, 46+1))]\n",
    "tmpseas1 = ee.List(tmpseas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2002\n",
    "\n",
    "# climatology\n",
    "yearp5 = ee.Number(year).add(5)\n",
    "start_date = ee.Date.fromYMD(year,1,1)\n",
    "end_date = ee.Date.fromYMD(yearp5,12,31)\n",
    "MOD09ndviY = MOD09ndvi.filterDate(start_date, end_date)\n",
    "MinNDVI = MOD09ndviY.min()\n",
    "\n",
    "# climatology 5 years (monthly composites)\n",
    "seasons = ee.ImageCollection.fromImages(tmpseas1.map(clim5y)) # problems start here!!!\n",
    "\n",
    "frame  = 8*3\n",
    "nodata = -9999\n",
    "seasons2 = linearInterp(seasons, frame, nodata)\n",
    "\n",
    "count_valid = seasons2.select('qc').count()\n",
    "smoothed = seasons2.map(filt_smoothed)\n",
    "smoothed = smoothed.select('NDVI')\n",
    "\n",
    "#Get the timestamp from the most recent image in the reference collection.\n",
    "time0 = smoothed.first().get('system:time_start')\n",
    "\n",
    "# Rename the first band 'NDVI'.\n",
    "first = ee.List([ee.Image(0).set('system:time_start', time0).select([0],['NDVI']).toFloat()])\n",
    "\n",
    "# Since the return type of iterate is unknown, it needs to be cast to a List.\n",
    "cumulative = ee.ImageCollection(ee.List(smoothed.iterate(accumulate, first)))\n",
    "\n",
    "# normalise\n",
    "last = cumulative.sort('system:time_start', False).first()\n",
    "last = last.updateMask(last.gte(1.5))\n",
    "\n",
    "# cumulative map normalised\n",
    "cumulativeNorm = cumulative.map(cum_dividelast)\n",
    "\n",
    "# deviations (these are described in the document sent by Alessandro)\n",
    "cumulativeStd10 = cumulativeNorm.map(deviations_calc)\n",
    "\n",
    "# calculate the mean of the deviations\n",
    "cumulativeStd10_mean = cumulativeStd10.mean().multiply(10000)\n",
    "cumulativeStd10_mean = cumulativeStd10_mean.updateMask(last.gte(9))\n",
    "cumulativeStd10_mean_at_5km = cumulativeStd10_mean.reproject(crs = 'SR-ORG:6974',scale = 463.3127165275).reduceResolution(ee.Reducer.mean(), False, 65536).reproject(ee.Projection('EPSG:4326').scale(0.05, 0.05)).updateMask(1)\n",
    "\n",
    "# mask out results for areas where there is forest\n",
    "cumulativeStd10_mean_at_5km1 = cumulativeStd10_mean_at_5km.updateMask(forestmask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMALL GRID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi1 = ee.Geometry.Polygon(smallgrid.geometry().getInfo().get('coordinates'))\n",
    "\n",
    "task = ee.batch.Export.image.toDrive(image = cumulativeStd10_mean,description ='smallgridnoproj',folder=\"alessandro_metric\",\n",
    "                                     scale = 5000,fileFormat='GeoTIFF',\n",
    "                                    skipEmptyTiles = True, crs ='EPSG:4326',maxPixels=1e13,\n",
    "                                    region = roi1)\n",
    "task.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get random image for selected area\n",
    "listOfImages = cumulative.toList(cumulative.size())\n",
    "secondImage = ee.Image(listOfImages.get(2)).clip(smallgrid)\n",
    "# export image\n",
    "task = ee.batch.Export.image.toDrive(image = secondImage,description ='NDVI_small',folder=\"alessandro_metric\",\n",
    "                                     scale = 463.3127165275,fileFormat='GeoTIFF',\n",
    "                                    skipEmptyTiles = True, crs ='SR-ORG:6974',maxPixels=1e13,\n",
    "                                    region = roi1)\n",
    "task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geemap\n",
    "Map = geemap.Map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate palette\n",
    "pal = sns.color_palette(\"viridis\",20).as_hex()\n",
    "palette = {'min':0 , 'max':100, 'palette':pal}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map.addLayer(cumulativeStd10_mean,'','test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map.addLayer(smallgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d036c8a5c4354d10857da84f808c29be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[40, -100], controls=(WidgetControl(options=['position'], widget=HBox(children=(ToggleButton(value=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export test: different ways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create random image and export it. The image is uploaded afterwards. Projection: MODIS Sinusoidal resolution 463m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example polygon drawn on map (smalls)\n",
    "roi = ee.FeatureCollection(Map.draw_features)\n",
    "roi1 = ee.Geometry.Polygon(roi.geometry().getInfo().get('coordinates'))\n",
    "\n",
    "# get random image for selected area\n",
    "listOfImages = cumulative.toList(cumulative.size())\n",
    "secondImage = ee.Image(listOfImages.get(2)).clip(roi)\n",
    "#secondImage.projection().nominalScale().getInfo()\n",
    "\n",
    "# export image\n",
    "task = ee.batch.Export.image.toDrive(image = secondImage,description ='NDVI_small',folder=\"alessandro_metric\",\n",
    "                                     scale = 463.3127165275,fileFormat='GeoTIFF',\n",
    "                                    skipEmptyTiles = True, crs ='SR-ORG:6974',maxPixels=1e13,\n",
    "                                    region = roi1)\n",
    "task.start()\n",
    "#secondImage.projection().nominalScale().getInfo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation of standard deviations following guido's procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an image similar to the obtained via the cumulation procedure.\n",
    "coll = ee.List([])\n",
    "coll = coll.add(testarea)\n",
    "coll = coll.add(testarea)\n",
    "coll1 =  ee.ImageCollection(coll)\n",
    "collmed =  coll1.median()\n",
    "# reduceNeighborhood stuff\n",
    "imagered = collmed.select('b1').reproject(crs = 'SR-ORG:6974', scale = 463.3127165275).reduceNeighborhood(reducer = 'stdDev',\n",
    "kernel = ee.Kernel.square(6, 'pixels'),skipMasked=True).rename('stdDev')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare area of interest (drawn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example polygon drawn on map (smalls)\n",
    "roi = ee.FeatureCollection(Map.draw_features)\n",
    "roi1 = ee.Geometry.Polygon(roi.geometry().getInfo().get('coordinates'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export when not reprojected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export image\n",
    "task = ee.batch.Export.image.toDrive(image = imagered,description ='im_noreproj',folder=\"alessandro_metric\",\n",
    "                                     scale = 5000,fileFormat='GeoTIFF',\n",
    "                                    skipEmptyTiles = True, crs ='EPSG:4326',maxPixels=1e13,\n",
    "                                    region = roi1)\n",
    "task.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export when reprojected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagered1 = imagered.reproject(crs = 'SR-ORG:6974',scale = 463.3127165275).reduceResolution(ee.Reducer.mean(), False, 65536).reproject(ee.Projection('EPSG:4326').scale(0.05, 0.05)).updateMask(1)\n",
    "#imagered1 = imagered.reproject(ee.Projection('EPSG:4326').scale(0.05, 0.05))\n",
    "\n",
    "\n",
    "# export image\n",
    "task = ee.batch.Export.image.toDrive(image = imagered1,description ='im_reproj1',folder=\"alessandro_metric\",\n",
    "                                     scale = 5000,fileFormat='GeoTIFF',\n",
    "                                    skipEmptyTiles = True, crs ='EPSG:4326',maxPixels=1e13,\n",
    "                                    region = roi1)\n",
    "task.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation of standard deviation using my smallgrid and export as csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Export using the tile method. File to use is Guido's reprojected 5km file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#polyl = list(range(1,2026+1))\n",
    "polyl = list(range(1,10+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-08f64c2a3a8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                     \u001b[0mskipEmptyTiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'EPSG:4326'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxPixels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e13\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                                     region = roi1)\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/ee/batch.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXPORT_IMAGE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexportImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXPORT_MAP\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexportMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/ee/data.py\u001b[0m in \u001b[0;36mexportImage\u001b[0;34m(request_id, params)\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_use_cloud_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m     return _prepare_and_run_export(\n\u001b[0m\u001b[1;32m   1353\u001b[0m         \u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m         _get_cloud_api_resource().projects().image().export)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/ee/data.py\u001b[0m in \u001b[0;36m_prepare_and_run_export\u001b[0;34m(request_id, params, export_endpoint)\u001b[0m\n\u001b[1;32m   1478\u001b[0m         params['expression'], for_cloud_api=True)\n\u001b[1;32m   1479\u001b[0m   \u001b[0mnum_retries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMAX_RETRIES\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrequest_id\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m   return _execute_cloud_call(\n\u001b[0m\u001b[1;32m   1481\u001b[0m       \u001b[0mexport_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_get_projects_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m       num_retries=num_retries)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/ee/data.py\u001b[0m in \u001b[0;36m_execute_cloud_call\u001b[0;34m(call, num_retries)\u001b[0m\n\u001b[1;32m    343\u001b[0m   \"\"\"\n\u001b[1;32m    344\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mgoogleapiclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHttpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0m_translate_cloud_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/googleapiclient/_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mpositional_parameters_enforcement\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPOSITIONAL_WARNING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpositional_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0;31m# Handle retries for server-side errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m         resp, content = _retry_request(\n\u001b[0m\u001b[1;32m    893\u001b[0m             \u001b[0mhttp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0mnum_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(http, num_retries, req_type, sleep, rand, uri, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0;31m# Retry on SSL errors and socket timeout errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_ssl_SSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mssl_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/google_auth_httplib2.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, uri, method, body, headers, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;31m# Make the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         response, content = self.http.request(\n\u001b[0m\u001b[1;32m    198\u001b[0m             uri, method, body=body, headers=request_headers, **kwargs)\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/httplib2/__init__.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, uri, method, body, headers, redirections, connection_type)\u001b[0m\n\u001b[1;32m   1946\u001b[0m                     \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1947\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1948\u001b[0;31m                     (response, content) = self._request(\n\u001b[0m\u001b[1;32m   1949\u001b[0m                         \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1950\u001b[0m                         \u001b[0mauthority\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/httplib2/__init__.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, conn, host, absolute_uri, request_uri, method, body, headers, redirections, cachekey)\u001b[0m\n\u001b[1;32m   1619\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1621\u001b[0;31m         (response, content) = self._conn_request(\n\u001b[0m\u001b[1;32m   1622\u001b[0m             \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/httplib2shim/__init__.py\u001b[0m in \u001b[0;36m_conn_request\u001b[0;34m(self, conn, request_uri, method, body, headers)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             urllib3_response = self.pool.request(\n\u001b[0m\u001b[1;32m    141\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0mfull_uri\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/urllib3/request.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             return self.request_encode_body(\n\u001b[0m\u001b[1;32m     80\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             )\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/urllib3/request.py\u001b[0m in \u001b[0;36mrequest_encode_body\u001b[0;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mextra_kw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3/dist-packages/urllib3/poolmanager.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0mredirect_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mredirect\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_redirect_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    666\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    419\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    414\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1345\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Remember year!\n",
    "for poly in polyl:\n",
    "    print(poly)\n",
    "    # filter a given square\n",
    "    onesquare = smallgrid.filterMetadata('polyID','equals',poly)\n",
    "    roi1 = ee.Geometry.Polygon(onesquare.geometry().getInfo().get('coordinates'))\n",
    "    # export tile\n",
    "    filename = 'Y_2002_'+str(poly)\n",
    "    task = ee.batch.Export.image.toDrive(image = cumulativeStd10_mean_at_5km1,description =filename,folder=\"alessandro_metric\",\n",
    "                                     scale = 5565.974539663679,fileFormat='GeoTIFF',\n",
    "                                    skipEmptyTiles = True, crs ='EPSG:4326',maxPixels=1e13,\n",
    "                                    region = roi1)\n",
    "    task.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export using the tile method. Bigger tile and previous steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask_5km = ee.Image('users/marcogirardello/phenoutils/pheno_grid').int()\n",
    "roi = worldgrid.filterMetadata('polyID','equals',136)\n",
    "roi1 = ee.Geometry.Polygon(roi.geometry().getInfo().get('coordinates'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cumulativeNorm.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export image\n",
    "task = ee.batch.Export.image.toDrive(image = image,description ='tile1_01',folder=\"alessandro_metric\",\n",
    "                                     scale = 463.3127165275,fileFormat='GeoTIFF',\n",
    "                                    skipEmptyTiles = True, crs ='EPSG:4326',maxPixels=1e13,\n",
    "                                    region = roi1)\n",
    "task.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export as csv files. Starts from a previous step from Guido's one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deviations (these are described in the document sent by Alessandro)\n",
    "cumulativeStd10 = cumulativeNorm.map(deviations_calc)\n",
    "\n",
    "# calculate the mean of the deviations\n",
    "cumulativeStd10_mean = cumulativeStd10.mean().multiply(10000)\n",
    "cumulativeStd10_mean = cumulativeStd10_mean.updateMask(last.gte(9))\n",
    "cumulativeStd10_mean_at_5km = cumulativeStd10_mean.reproject(crs = 'SR-ORG:6974',scale = 463.3127165275).reduceResolution(ee.Reducer.mean(), False, 65536).reproject(ee.Projection('EPSG:4326').scale(0.05, 0.05)).updateMask(1)\n",
    "\n",
    "# mask out results for areas where there is forest\n",
    "cumulativeStd10_mean_at_5km1 = cumulativeStd10_mean_at_5km.updateMask(forestmask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cumulativeNorm.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_5km = ee.Image('users/marcogirardello/phenoutils/pheno_grid').int()\n",
    "onesquare = worldgrid.filterMetadata('polyID','equals',136)\n",
    "# convert 5km grid into vectors (pixels become polygons!)\n",
    "vectors = mask_5km.reduceToVectors(crs = mask_5km.projection(),geometry = onesquare,scale =100,\n",
    "                                           geometryType = 'polygon',eightConnected = False, labelProperty ='zone',\n",
    "                                           reducer= ee.Reducer.countEvery(),maxPixels= 1e13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate statistics of interest (standard deviation)\n",
    "stats = image.reduceRegions(collection = vectors,reducer = ee.Reducer.stdDev(),\n",
    "                                          scale = 463.3127165275)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats1 = stats.map(convert)\n",
    "# filename (currus)\n",
    "filename = 'currus'\n",
    "\n",
    "task= ee.batch.Export.table.toDrive(collection = stats1,description = filename,folder = \"alessandro_metric_csv\",\n",
    "                                        fileFormat = 'CSV')\n",
    "task.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export in the form of csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_5km = ee.Image('users/marcogirardello/phenoutils/pheno_grid').int()\n",
    "onesquare = worldgrid.filterMetadata('polyID','equals',136)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert 5km grid into vectors (pixels become polygons!)\n",
    "vectors = mask_5km.reduceToVectors(crs = mask_5km.projection(),geometry = onesquare,scale =100,\n",
    "                                           geometryType = 'polygon',eightConnected = False, labelProperty ='zone',\n",
    "                                           reducer= ee.Reducer.countEvery(),maxPixels= 1e13)\n",
    "# calculate statistics of interest (standard deviation)\n",
    "stats = cumulativeStd10_mean_at_5km1.reduceRegions(collection = vectors,reducer = ee.Reducer.mean(),\n",
    "                                          scale = 5000)\n",
    "# convert to dictionary (set geometry to null!)\n",
    "stats1 = stats.map(convert)\n",
    "\n",
    "# filename (currus)\n",
    "filename = 'currus'\n",
    "\n",
    "task= ee.batch.Export.table.toDrive(collection = stats1,description =filename,folder=\"phenology_csv\",\n",
    "                                        fileFormat='CSV')\n",
    "task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# polygon numbers for broad areas\n",
    "polygons = list(range(1, 2+1))\n",
    "for polygon in polygons:\n",
    "    print(polygon)\n",
    "    # subset one broad area\n",
    "    onesquare = export_grid.filterMetadata('polyID','equals',polygon)\n",
    "    # convert 5km grid into vectors (pixels become polygons!)\n",
    "    vectors = mask_5km.reduceToVectors(crs = mask_5km.projection(),geometry = onesquare,scale =100,\n",
    "                                           geometryType = 'polygon',eightConnected = False, labelProperty ='zone',\n",
    "                                           reducer= ee.Reducer.countEvery(),maxPixels= 1e13)\n",
    "    # calculate statistics of interest (standard deviation)\n",
    "    stats = tmpimage1.reduceRegions(collection = vectors,reducer = ee.Reducer.stdDev(),\n",
    "                                          scale = 463.3127165275)\n",
    "    # convert to dictionary (set geometry to null!)\n",
    "    stats1 = stats.map(convert)\n",
    "    # filename\n",
    "    filename = 'DOY50_sd_v6_'+str(polygon)\n",
    "    #Export the FeatureCollection.\n",
    "    task= ee.batch.Export.table.toDrive(collection = stats1,description =filename,folder=\"phenology_csv\",\n",
    "                                        fileFormat='CSV')\n",
    "    task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter smoothed map\n",
    "def filt_smoothed(image):\n",
    "    tmp = image.unmask()\n",
    "    return tmp.updateMask(count_valid.gte(7))\n",
    "year = 2002\n",
    "# climatology\n",
    "yearp5 = ee.Number(year).add(5)\n",
    "start_date = ee.Date.fromYMD(year,1,1)\n",
    "end_date = ee.Date.fromYMD(yearp5,12,31)\n",
    "MOD09ndviY = MOD09ndvi.filterDate(start_date, end_date)\n",
    "# climatology 5 years (monthly composites)\n",
    "seasons = ee.ImageCollection.fromImages(tmpseas1.map(clim5y))\n",
    "# set the width of the temporal smoothing bandwidth (in days)\n",
    "bw = 35\n",
    "# This field contains UNIX time in milliseconds\n",
    "timeField = 'system:time_start'\n",
    "# sort by start time\n",
    "filteredMODIS = seasons.sort(\"system:time_start\")\n",
    "# Smoothing\n",
    "join = ee.Join.saveAll(matchesKey = 'images')\n",
    "diffFilter = ee.Filter.maxDifference(difference =1000 * 60 * 60 * 24 * bw, \n",
    " leftField = timeField,rightField = timeField)\n",
    "threeNeighborJoin = join.apply(primary = filteredMODIS,secondary = filteredMODIS,condition = diffFilter)\n",
    "# get smoothed collection\n",
    "smoothed = ee.ImageCollection(threeNeighborJoin.map(smooth_func))\n",
    "# mask smoothed dataset\n",
    "#smoothed_masked = smoothed.map(mask_smt)\n",
    "# count valid images\n",
    "count_valid = smoothed.select('mean').count()\n",
    "# mask smoothed dataset\n",
    "smoothed = smoothed.map(filt_smoothed)\n",
    "# select mean band\n",
    "smoothed = smoothed.select('mean')\n",
    "# Get the timestamp from the most recent image in the reference collection.\n",
    "time0 = smoothed.first().get('system:time_start')\n",
    "# Rename the first band 'NDVI'.\n",
    "first = ee.List([ee.Image(0).set('system:time_start', time0).select([0], ['mean']).toFloat()])\n",
    "# Create an ImageCollection of cumulative anomaly images by iterating.\n",
    "# Since the return type of iterate is unknown, it needs to be cast to a List.\n",
    "cumulative = ee.ImageCollection(ee.List(smoothed.iterate(accumulate, first)))\n",
    "# normalise\n",
    "last = cumulative.sort('system:time_start', False).first()\n",
    "last = last.updateMask(last.gte(9))\n",
    "# cumulative map normalised\n",
    "cumulativeNorm = cumulative.map(cum_dividelast)\n",
    "# deviations (these are described in the document sent by Alessandro)\n",
    "cumulativeStd10 = cumulativeNorm.map(deviations_calc)\n",
    "# calculate the mean of the deviations\n",
    "cumulativeStd10_mean = cumulativeStd10.mean().multiply(10000)\n",
    "cumulativeStd10_mean = cumulativeStd10_mean.updateMask(last.gte(12))\n",
    "#cumulativeStd10_mean1 = cumulativeStd10_mean.updateMask(forestmask.gt(0))\n",
    "#Map.addLayer(cumulativeStd10_mean1,palette,'metric 6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for year in list(range(2002,2002)):\n",
    "    # climatology\n",
    "    yearp5 = ee.Number(year).add(5)\n",
    "    start_date = ee.Date.fromYMD(year,1,1)\n",
    "    end_date = ee.Date.fromYMD(yearp5,12,31)\n",
    "    MOD09ndviY = MOD09ndvi.filterDate(start_date, end_date)\n",
    "    # climatology 5 years (monthly composites)\n",
    "    seasons = ee.ImageCollection.fromImages(tmpseas1.map(clim5y))\n",
    "    # set the width of the temporal smoothing bandwidth (in days)\n",
    "    bw = 35\n",
    "    # This field contains UNIX time in milliseconds\n",
    "    timeField = 'system:time_start'\n",
    "    # sort by start time\n",
    "    filteredMODIS = seasons.sort(\"system:time_start\")\n",
    "    # Smoothing\n",
    "    join = ee.Join.saveAll(matchesKey = 'images')\n",
    "    diffFilter = ee.Filter.maxDifference(difference =1000 * 60 * 60 * 24 * bw, \n",
    "                                         leftField = timeField,rightField = timeField)\n",
    "    threeNeighborJoin = join.apply(primary = filteredMODIS,secondary = filteredMODIS,condition = diffFilter)\n",
    "    # get smoothed collection\n",
    "    smoothed = ee.ImageCollection(threeNeighborJoin.map(smooth_func))\n",
    "    # mask smoothed dataset\n",
    "    #smoothed_masked = smoothed.map(mask_smt)\n",
    "    # count valid images\n",
    "    count_valid = smoothed.select('NDVI').count()\n",
    "    # mask smoothed dataset\n",
    "    smoothed = smoothed.map(filt_smoothed)\n",
    "    # select mean band\n",
    "    smoothed = smoothed.select('mean')\n",
    "    # Get the timestamp from the most recent image in the reference collection.\n",
    "    time0 = smoothed.first().get('system:time_start')\n",
    "    # Rename the first band 'NDVI'.\n",
    "    first = ee.List([ee.Image(0).set('system:time_start', time0).select([0], ['mean']).toFloat()])\n",
    "    # Create an ImageCollection of cumulative anomaly images by iterating.\n",
    "    # Since the return type of iterate is unknown, it needs to be cast to a List.\n",
    "    cumulative = ee.ImageCollection(ee.List(smoothed.iterate(accumulate, first)))\n",
    "    # normalise\n",
    "    last = cumulative.sort('system:time_start', False).first()\n",
    "    last = last.updateMask(last.gte(9))\n",
    "    # cumulative map normalised\n",
    "    cumulativeNorm = cumulative.map(cum_dividelast)\n",
    "    # deviations (these are described in the document sent by Alessandro)\n",
    "    cumulativeStd10 = cumulativeNorm.map(deviations_calc)\n",
    "    # calculate the mean of the deviations\n",
    "    cumulativeStd10_mean = cumulativeStd10.mean().multiply(10000)\n",
    "    cumulativeStd10_mean = cumulativeStd10_mean.updateMask(last.gte(9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map.addLayer(test,palette,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
