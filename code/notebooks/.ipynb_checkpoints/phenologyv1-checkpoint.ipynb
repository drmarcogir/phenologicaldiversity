{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create phenology datasets and export them to google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load required modules\n",
    "import ee\n",
    "ee.Initialize()\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load leaflet interactive map\n",
    "import geemap\n",
    "Map = geemap.Map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCD12Q2 v006 phenology product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for extracting quality bits\n",
    "def getQABits(image, start, end, mascara):\n",
    "    # Compute the bits we need to extract.\n",
    "    pattern = 0\n",
    "    for i in range(start,end+1):\n",
    "        pattern += 2**i\n",
    "    # Return a single band image of the extracted QA bits, giving the     band a new name.\n",
    "    return image.select([0], [mascara]).bitwiseAnd(pattern).rightShift(start)\n",
    "    \n",
    "# function for filtering image based on quality bits\n",
    "def mask_pixelsall(bstart,bend):\n",
    "    def maskPixels(image0):\n",
    "        tmp = image0.select('QA_Detailed_1')\n",
    "        quality = getQABits(tmp, bstart, bend, 'QA_Detailed_1')\n",
    "        # Create a mask that filters out undesired areas\n",
    "        mask = quality.eq(0).Or(quality.eq(1)).Or(quality.eq(2))\n",
    "        return image0.updateMask(mask) \n",
    "    return(maskPixels)\n",
    "\n",
    "# function for masking areas where there have not land use changes. This layer was created using the ESA cci map\n",
    "def mask_image(image):\n",
    "    image = image.updateMask(MakMarco.eq(1))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- load datasets\n",
    "# load MODIS phenology product\n",
    "modis_phenoprod = ee.ImageCollection('MODIS/006/MCD12Q2')\n",
    "# load mask of unchanged forest pixels\n",
    "MakMarco = ee.Image(\"users/marcogirardello/mask_unchanged_500m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of years\n",
    "years = list(range(2001, 2016+1))\n",
    "\n",
    "for year in years:\n",
    "    #print(year)\n",
    "    # filter for year of interest\n",
    "    pheno_tmp = modis_phenoprod.filter(ee.Filter.date(str(year)+'-01-01', str(year+1)+'-01-01'))\n",
    "    # ------- Greenup\n",
    "    GUP = pheno_tmp.select(['Greenup_1','QA_Detailed_1'])\n",
    "    # only take pixels above a certain threshold level\n",
    "    GUP1 = GUP.map(mask_pixelsall(bstart=0,bend=1)).select('Greenup_1').first()\n",
    "    # filter using mask where pixels have been stable\n",
    "    GUP2 = GUP1.updateMask(MakMarco.eq(1))\n",
    "    # calculate standard deviation\n",
    "    GUP_sd = GUP2.reduceNeighborhood(reducer='stdDev',kernel= ee.Kernel.square(6, 'pixels'),skipMasked =True)\n",
    "    # create filename\n",
    "    filename = 'GUP_sd_'+str(year)\n",
    "    # export GUP to google drive\n",
    "    task = ee.batch.Export.image.toDrive(image=GUP_sd,description=filename,folder=\"curruspito_phenology\",\n",
    "                                         scale=5565.974539663679,fileFormat='GeoTIFF',skipEmptyTiles=True,\n",
    "                                         crs = 'EPSG:4326',maxPixels = 1e13)\n",
    "    task.start()\n",
    "    # ------- Peak\n",
    "    # subset Peak for given year\n",
    "    Peak = pheno_tmp.select(['Peak_1','QA_Detailed_1'])\n",
    "    # only take pixels above a certain threshold level\n",
    "    Peak1 = Peak.map(mask_pixelsall(bstart=6,bend=7)).select('Peak_1').first()\n",
    "    # filter using mask where pixels have been stable\n",
    "    Peak2 = Peak1.updateMask(MakMarco.eq(1))\n",
    "    # calculate standard deviation\n",
    "    Peak2_sd = Peak2.reduceNeighborhood(reducer='stdDev',kernel= ee.Kernel.square(6, 'pixels'),skipMasked =True)\n",
    "    # create filename\n",
    "    filename = 'Peak_sd_'+str(year)\n",
    "    # export Peak to google drive\n",
    "    task = ee.batch.Export.image.toDrive(image=Peak2_sd,description=filename,folder=\"curruspito_phenology\",\n",
    "                                         scale=5565.974539663679,fileFormat='GeoTIFF',skipEmptyTiles=True,\n",
    "                                         crs = 'EPSG:4326',maxPixels = 1e13)\n",
    "    task.start()\n",
    "    # ------- Dormancy\n",
    "    Dormancy = pheno_tmp.select(['Dormancy_1','QA_Detailed_1'])\n",
    "    # only take pixels above a certain threshold level\n",
    "    Dormancy1 = Dormancy.map(mask_pixelsall(bstart=12,bend=13)).select('Dormancy_1').first()\n",
    "    # filter using mask where pixels have been stable\n",
    "    Dormancy2 = Dormancy1.updateMask(MakMarco.eq(1))\n",
    "    # calculate standard deviation\n",
    "    Dormancy2_sd = Dormancy2.reduceNeighborhood(reducer='stdDev',kernel= ee.Kernel.square(6, 'pixels'),skipMasked =True)\n",
    "    # create filename\n",
    "    filename = 'Dormancy_sd_'+str(year)\n",
    "    # export Dormancy to google drive\n",
    "    task = ee.batch.Export.image.toDrive(image=Dormancy2_sd,description=filename,folder=\"curruspito_phenology\",\n",
    "                                         scale=5565.974539663679,fileFormat='GeoTIFF',skipEmptyTiles=True,\n",
    "                                         crs = 'EPSG:4326',maxPixels = 1e13)\n",
    "    task.start()\n",
    "    # ------- Season length\n",
    "    season_length = Dormancy2.subtract(GUP2)\n",
    "    # calculate standard deviation\n",
    "    SL_sd = season_length.reduceNeighborhood(reducer='stdDev',kernel= ee.Kernel.square(6, 'pixels'),skipMasked =True)\n",
    "    # create filename\n",
    "    filename = 'SL_sd_'+str(year)\n",
    "    # export Dormancy to google drive\n",
    "    task = ee.batch.Export.image.toDrive(image=SL_sd,description=filename,folder=\"curruspito_phenology\",\n",
    "                                         scale=5565.974539663679,fileFormat='GeoTIFF',skipEmptyTiles=True,\n",
    "                                         crs = 'EPSG:4326',maxPixels = 1e13)\n",
    "    task.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- load datasets\n",
    "# load MODIS data (daily 500m resolution)\n",
    "collection = ee.ImageCollection('MODIS/006/MOD09GA').filterDate('2001-01-01', '2019-12-31')\n",
    "# mask of pixels that were unchanged (until 2015)\n",
    "MakMarco = ee.Image(\"users/marcogirardello/mask_unchanged_500m\")\n",
    "# Region for cropping final datasets\n",
    "Rectangle1 = ee.Geometry.Polygon(\n",
    "        [[[-178.2918491139962, 73.88593845172474],\n",
    "          [-178.2918491139962, -61.42493117272831],\n",
    "          [179.98940088600375, -61.42493117272831],\n",
    "          [179.98940088600375, 73.88593845172474]]], None, False)\n",
    "# grid for export to assets\n",
    "worldgrid = ee.FeatureCollection('users/marcogirardello/grid_export_phenology')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set dates\n",
    "start_date = ee.Date.fromYMD(2001, 1, 1)\n",
    "end_date   = ee.Date.fromYMD(2019, 12, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----- Required functions\n",
    "# add NDVI to data\n",
    "def addNDVI(image):\n",
    "    image = image.updateMask(MakMarco.eq(1))\n",
    "    return image.addBands(image.normalizedDifference(['sur_refl_b02','sur_refl_b01']).rename('NDVI')).float()\n",
    "\n",
    "# function for extracting quality bits\n",
    "def getQABits(image, start, end, mascara):\n",
    "    # Compute the bits we need to extract.\n",
    "    pattern = 0\n",
    "    for i in range(start,end+1):\n",
    "        pattern += 2**i\n",
    "    # Return a single band image of the extracted QA bits, giving the     band a new name.\n",
    "    return image.select([0], [mascara]).bitwiseAnd(pattern).rightShift(start)\n",
    "\n",
    "# mask out low quality pixels (based on flags)\n",
    "def maskPixels(image0):\n",
    "    #Select the QA band\n",
    "    QA = image0.select('state_1km')\n",
    "    # Get the land_water_flag bits\n",
    "    landWaterFlag = getQABits(QA, 3, 5, 'land_water_flag')\n",
    "    #Get the cloud_state bits and find cloudy areas.\n",
    "    cloud = getQABits(QA, 0, 1, 'cloud_state').expression(\"b(0) == 1 || b(0) == 2\")\n",
    "    # Get the cloud_shadow bit\n",
    "    cloudShadows = getQABits(QA, 2, 2, 'cloud_shadow')\n",
    "    # Get the Pixel is adjacent to cloud bit\n",
    "    cloudAdjacent = getQABits(QA, 13, 13, 'cloud_adj')\n",
    "    # Get the internal cloud flag\n",
    "    cloud2 = getQABits(QA, 10, 10, 'cloud_internal')\n",
    "    # Get the internal fire flag\n",
    "    fire = getQABits(QA, 11, 11, 'fire_internal')\n",
    "    # Get the MOD35 snow/ice flag\n",
    "    snow1 = getQABits(QA, 12, 12, 'snow_MOD35')\n",
    "    # Get the internal snow flag\n",
    "    snow2 = getQABits(QA, 15, 15, 'snow_internal')\n",
    "    # create mask\n",
    "    mask = landWaterFlag.eq(1).And(cloud.Not()).And(cloudShadows.Not()).And(cloudAdjacent.Not()).And(cloud2.Not()).And(fire.Not()).And(snow1.Not()).And(snow2.Not())\n",
    "    return image0.updateMask(mask) \n",
    "            \n",
    "\n",
    "# utility function for temporal smoothing\n",
    "def smooth_func(image):\n",
    "    collection = ee.ImageCollection.fromImages(image.get('images'))\n",
    "    return ee.Image(image).addBands(collection.mean().rename('mean'))\n",
    "\n",
    "# masked smoothed dataset\n",
    "def mask_smt(image):\n",
    "    img = image.select('NDVI')\n",
    "    img.updateMask(img.gt(0))\n",
    "    return image.addBands(img)\n",
    "\n",
    "# masked smoothed dataset\n",
    "def unmask_img(image):\n",
    "    return image.unmask()\n",
    "\n",
    "# function for accumulating NDVI\n",
    "def accumulate(image,list):\n",
    "    # Get the latest cumulative NDVI of the list with\n",
    "    # get(-1).  Since the type of the list argument to the function is unknown,\n",
    "    # it needs to be cast to a List.  Since the return type of get() is unknown,\n",
    "    # cast it to Image.\n",
    "    previous = ee.Image(ee.List(list).get(-1)).toFloat()\n",
    "    # Add the current anomaly to make a new cumulative NDVI image and Propagate metadata to the new image.\n",
    "    added = image.toFloat().add(previous).toFloat().set('system:time_start', image.get('system:time_start'))\n",
    "    return ee.List(list).add(added)\n",
    "\n",
    "\n",
    "# add day of the year\n",
    "def addDOY(image):\n",
    "    return image.addBands(ee.Image.constant(ee.Number.parse(image.date().format('D'))).rename('DOY').float())\n",
    "\n",
    "# calculate 50th percentile\n",
    "def perc_50(img):\n",
    "    # subtract the 50th percentile from each image, square to remove negative, append summed difference to image \n",
    "    dif = ee.Image(img).select(['mean']).subtract(Sum_NDVI.divide(2)).pow(ee.Image.constant(2)).multiply(-1).rename('quality')\n",
    "    return img.addBands(dif)\n",
    "\n",
    "# calculate 25th percentile\n",
    "def perc_25(img):\n",
    "    dif = ee.Image(img).select(['mean']).subtract(Sum_NDVI.divide(4)).pow(ee.Image.constant(2)).multiply(-1).rename('quality')\n",
    "    return img.addBands(dif)\n",
    "\n",
    "# calculate 75th percentile\n",
    "def perc_75(img):\n",
    "    dif = ee.Image(img).select(['mean']).subtract(Sum_NDVI.divide(4).multiply(3)).pow(ee.Image.constant(2)).multiply(-1).rename('quality')\n",
    "    return img.addBands(dif)\n",
    "\n",
    "# rename band\n",
    "def rename_d(image):\n",
    "    return Final_output_.select([b]).rename('value')\n",
    "\n",
    "# smoothed mask for NDVI max\n",
    "def mask_maxndvi(image):\n",
    "    image = image.updateMask(count_valid.gte(30))\n",
    "    return image.updateMask(image.select('NDVI').gt(0))\n",
    "\n",
    "# rename ndvi for max ndvi dataset\n",
    "def rename_maxndvi(b):\n",
    "    return Final_output_.select([b]).rename('value')\n",
    "\n",
    "# filter pixels greater than 10 %\n",
    "def ndvi_filter10(image):\n",
    "    return image.updateMask(image.gte(MaxNDVI_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask pixels on the basis of quality flags\n",
    "MOD09masked = collection.filterDate(start_date, end_date).map(maskPixels)\n",
    "# add NDVI band\n",
    "MOD09ndvi = MOD09masked.map(addNDVI).select('NDVI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through years\n",
    "years = list(range(2001, 2019+1))\n",
    "\n",
    "for year in years:\n",
    "    #print(year)\n",
    "    # start and end date for a given year\n",
    "    start_date = ee.Date.fromYMD(year,1,1)\n",
    "    end_date = ee.Date.fromYMD(year,12,31)\n",
    "    # filter dataset for a given year\n",
    "    MOD09ndviY = MOD09ndvi.filterDate(start_date, end_date)\n",
    "    # value for the temporal smoothing bandwidth (21 days)\n",
    "    bw = 21\n",
    "    # This field contains UNIX time in milliseconds\n",
    "    timeField = 'system:time_start'\n",
    "    # sort collection by date\n",
    "    filteredMODIS = MOD09ndviY.sort('system:time_start')\n",
    "    # Smoothing\n",
    "    join = ee.Join.saveAll(matchesKey = 'images')\n",
    "    diffFilter = ee.Filter.maxDifference(difference =1000 * 60 * 60 * 24 * bw, \n",
    "                                     leftField = timeField,rightField = timeField)\n",
    "    threeNeighborJoin = join.apply(primary = filteredMODIS,secondary = filteredMODIS,condition = diffFilter)\n",
    "    # get smoothed collection\n",
    "    smoothed = ee.ImageCollection(threeNeighborJoin.map(smooth_func))\n",
    "    # mask smoothed dataset\n",
    "    smoothed_masked = smoothed.map(mask_smt)\n",
    "    # count valid images\n",
    "    count_valid = smoothed_masked.select('NDVI').count()\n",
    "    # unmask smoothed dataset\n",
    "    smoothed = smoothed.map(unmask_img)\n",
    "    # select mean band\n",
    "    smoothed = smoothed.select('mean')\n",
    "    # Define reference conditions from the first  year of data.\n",
    "    # Sort chronologically in descending order.\n",
    "    reference = smoothed.sort('system:time_start', True)\n",
    "    # Get the timestamp from the most recent image in the reference collection.\n",
    "    time0 = reference.first().get('system:time_start')\n",
    "    # Use imageCollection.iterate() to make a collection of cumulative NDVI over time.\n",
    "    # Rename the first band 'NDVI'.\n",
    "    first = ee.List([ee.Image(0).set('system:time_start', time0).select([0], ['mean']).toFloat()])\n",
    "    # cumulate NDVI\n",
    "    cumulative = ee.ImageCollection(ee.List(reference.iterate(accumulate, first)))\n",
    "    # add day of the year\n",
    "    cumulativeDOI = cumulative.map(addDOY)\n",
    "    # sum NDVI\n",
    "    Sum_NDVI = smoothed.sum()\n",
    "    #--- compute 50th percentile\n",
    "    difFrom50 = cumulativeDOI.map(perc_50)\n",
    "    DOY50 = difFrom50.qualityMosaic('quality')\n",
    "    DOY50 = DOY50.updateMask(DOY50.select('mean').gt(0))\n",
    "    DOY50 = DOY50.updateMask(count_valid.gte(30))\n",
    "    # calculate standard deviation\n",
    "    SD_DOY = DOY50.select('DOY').reduceNeighborhood(reducer ='stdDev',kernel= ee.Kernel.square(6, 'pixels'),\n",
    "                                                skipMasked = True)\n",
    "    # save files\n",
    "    filename = 'PC_SD50_'+str(year)\n",
    "    task = ee.batch.Export.image.toDrive(image=SD_DOY,description=filename,folder=\"curruspito_phenology\",\n",
    "                                         scale=5565.974539663679,fileFormat='GeoTIFF',skipEmptyTiles=True,\n",
    "                                          crs = 'EPSG:4326',maxPixels = 1e13,region = Rectangle1)\n",
    "\n",
    "    task.start()\n",
    "    #--- compute 25th percentile\n",
    "    difFrom25 = cumulativeDOI.map(perc_25)\n",
    "    DOY25 = difFrom25.qualityMosaic('quality')\n",
    "    DOY25 = DOY25.updateMask(DOY25.select('mean').gt(0))\n",
    "    DOY25 = DOY25.updateMask(count_valid.gte(30))\n",
    "    # calculate standard deviation\n",
    "    SD_DOY = DOY25.select('DOY').reduceNeighborhood(reducer ='stdDev',kernel= ee.Kernel.square(6, 'pixels'),\n",
    "                                                skipMasked = True)\n",
    "    # save files\n",
    "    filename = 'PC_SD25_'+str(year)\n",
    "    task = ee.batch.Export.image.toDrive(image=SD_DOY,description=filename,folder=\"curruspito_phenology\",\n",
    "                                         scale=5565.974539663679,fileFormat='GeoTIFF',skipEmptyTiles=True,\n",
    "                                          crs = 'EPSG:4326',maxPixels = 1e13,region = Rectangle1)\n",
    "\n",
    "    task.start()\n",
    "    #--- compute 75th percentile\n",
    "    difFrom75 = cumulativeDOI.map(perc_75)\n",
    "    DOY75 = difFrom75.qualityMosaic('quality')\n",
    "    DOY75 = DOY75.updateMask(DOY75.select('mean').gt(0))\n",
    "    DOY75 = DOY75.updateMask(count_valid.gte(30))\n",
    "    # calculate standard deviation\n",
    "    SD_DOY = DOY75.select('DOY').reduceNeighborhood(reducer ='stdDev',kernel= ee.Kernel.square(6, 'pixels'),\n",
    "                                                skipMasked = True)\n",
    "    # save files\n",
    "    filename = 'PC_SD75_'+str(year)\n",
    "    task = ee.batch.Export.image.toDrive(image=SD_DOY,description=filename,folder=\"curruspito_phenology\",\n",
    "                                         scale=5565.974539663679,fileFormat='GeoTIFF',skipEmptyTiles=True,\n",
    "                                          crs = 'EPSG:4326',maxPixels = 1e13,region = Rectangle1)\n",
    "\n",
    "    task.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through years\n",
    "years = list(range(2001, 2019+1))\n",
    "\n",
    "for year in years:\n",
    "    #print(year)\n",
    "    # start and end date for a given year\n",
    "    start_date = ee.Date.fromYMD(year,1,1)\n",
    "    end_date = ee.Date.fromYMD(year,12,31)\n",
    "    # filter dataset for a given year\n",
    "    MOD09ndviY = MOD09ndvi.filterDate(start_date, end_date)\n",
    "    # value for the temporal smoothing bandwidth (14 days, different from the percentile one!!)\n",
    "    bw = 14\n",
    "    # This field contains UNIX time in milliseconds\n",
    "    timeField = 'system:time_start'\n",
    "    # sort collection by date\n",
    "    filteredMODIS = MOD09ndviY.sort('system:time_start')\n",
    "    # Smoothing\n",
    "    join = ee.Join.saveAll(matchesKey = 'images')\n",
    "    diffFilter = ee.Filter.maxDifference(difference =1000 * 60 * 60 * 24 * bw, \n",
    "                                     leftField = timeField,rightField = timeField)\n",
    "    threeNeighborJoin = join.apply(primary = filteredMODIS,secondary = filteredMODIS,condition = diffFilter)\n",
    "    # get smoothed collection\n",
    "    smoothed = ee.ImageCollection(threeNeighborJoin.map(smooth_func))\n",
    "    # mask smoothed dataset\n",
    "    smoothed_masked = smoothed.map(mask_smt)\n",
    "    # count valid images\n",
    "    count_valid = smoothed_masked.select('NDVI').count()\n",
    "    # unmask smoothed dataset\n",
    "    smoothed = smoothed.map(mask_maxndvi)\n",
    "    # add day of the year\n",
    "    NDVI_DOY = smoothed.map(addDOY)\n",
    "    # Quality mosaic\n",
    "    \n",
    "    ndviCollectionMax = NDVI_DOY.qualityMosaic('mean')\n",
    "    # calculate standard deviation\n",
    "    SD_DOY = ndviCollectionMax.select('DOY').reduceNeighborhood(reducer ='stdDev',kernel= ee.Kernel.square(6, 'pixels'),\n",
    "                                              skipMasked = True)\n",
    "    SD_DOY = ndviCollectionMax.select('DOY').reproject(crs = 'SR-ORG:6974',scale = 463.3127165275).reduceResolution(ee.Reducer.stdDev(), \n",
    "             False, 65536).reproject(ee.Projection('EPSG:4326').scale(0.05, 0.05)).updateMask(1) \n",
    "\n",
    "    # save files\n",
    "    filename = 'NDVIMAX_'+str(year)\n",
    "    task = ee.batch.Export.image.toDrive(image=SD_DOY,description=filename,folder=\"curruspito_phenology\",\n",
    "                                         scale=5565.974539663679,fileFormat='GeoTIFF',skipEmptyTiles=True,\n",
    "                                          crs = 'EPSG:4326',maxPixels = 1e13,region = Rectangle1)\n",
    "\n",
    "    task.start()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentiles calculated using the 10% NDVI rule (whole world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through years\n",
    "years = list(range(2001, 2019+1))\n",
    "# list of polygons\n",
    "polygons = list(range(1, 42+1))\n",
    "\n",
    "for year in years:\n",
    "    #print(year)\n",
    "    # start and end date for a given year\n",
    "    start_date = ee.Date.fromYMD(year,1,1)\n",
    "    end_date = ee.Date.fromYMD(year,12,31)\n",
    "    # filter dataset for a given year\n",
    "    MOD09ndviY = MOD09ndvi.filterDate(start_date, end_date)\n",
    "    # filter according to 10% rule\n",
    "    MaxNDVI_10 = MOD09ndviY.max().divide(10)\n",
    "    MOD09ndviY = MOD09ndviY.map(ndvi_filter10)\n",
    "    # value for the temporal smoothing bandwidth (21 days)\n",
    "    bw = 21\n",
    "    # This field contains UNIX time in milliseconds\n",
    "    timeField = 'system:time_start'\n",
    "    # sort collection by date\n",
    "    filteredMODIS = MOD09ndviY.sort('system:time_start')\n",
    "    # Smoothing\n",
    "    join = ee.Join.saveAll(matchesKey = 'images')\n",
    "    diffFilter = ee.Filter.maxDifference(difference =1000 * 60 * 60 * 24 * bw, \n",
    "                                     leftField = timeField,rightField = timeField)\n",
    "    threeNeighborJoin = join.apply(primary = filteredMODIS,secondary = filteredMODIS,condition = diffFilter)\n",
    "    # get smoothed collection\n",
    "    smoothed = ee.ImageCollection(threeNeighborJoin.map(smooth_func))\n",
    "    # mask smoothed dataset\n",
    "    smoothed_masked = smoothed.map(mask_smt)\n",
    "    # count valid images\n",
    "    count_valid = smoothed_masked.select('NDVI').count()\n",
    "    # unmask smoothed dataset\n",
    "    smoothed = smoothed.map(unmask_img)\n",
    "    # select mean band\n",
    "    smoothed = smoothed.select('mean')\n",
    "    # Define reference conditions from the first  year of data.\n",
    "    # Sort chronologically in descending order.\n",
    "    reference = smoothed.sort('system:time_start', True)\n",
    "    # Get the timestamp from the most recent image in the reference collection.\n",
    "    time0 = reference.first().get('system:time_start')\n",
    "    # Use imageCollection.iterate() to make a collection of cumulative NDVI over time.\n",
    "    # Rename the first band 'NDVI'.\n",
    "    first = ee.List([ee.Image(0).set('system:time_start', time0).select([0], ['mean']).toFloat()])\n",
    "    # cumulate NDVI\n",
    "    cumulative = ee.ImageCollection(ee.List(reference.iterate(accumulate, first)))\n",
    "    # normalise\n",
    "    last = cumulative.sort('system:time_start', False).first()\n",
    "    \n",
    "    # add day of the year\n",
    "    cumulativeDOI = cumulative.map(addDOY)\n",
    "    # sum NDVI\n",
    "    Sum_NDVI = smoothed.sum()\n",
    "    #--- compute 50th percentile\n",
    "    difFrom50 = cumulativeDOI.map(perc_50)\n",
    "    DOY50 = difFrom50.qualityMosaic('quality')\n",
    "    DOY50 = DOY50.updateMask(DOY50.select('mean').gt(0))\n",
    "    DOY50 = DOY50.updateMask(count_valid.gte(30))\n",
    "    for polygon in polygons:\n",
    "        print('DOY50 Year '+str(year)+' Polygon number '+str(polygon))\n",
    "        # subset polygon\n",
    "        tmp_poly = worldgrid.filterMetadata('polyID', 'equals', polygon).first().geometry()\n",
    "        # assetname\n",
    "        assetname = 'DOY50_'+str(year)+'_'+str(polygon)\n",
    "        # export tile\n",
    "        task = ee.batch.Export.image.toAsset(image=DOY50,description=assetname,assetId = 'users/marcogirardello/phenology/'+assetname,\n",
    "                                     scale=463.3127165275,crs = 'EPSG:4326',maxPixels = 1e13,region = tmp_poly)\n",
    "        task.start()\n",
    "    # calculate standard deviation\n",
    "    #SD_DOY = DOY50.select('DOY').reduceNeighborhood(reducer ='stdDev',kernel= ee.Kernel.square(6, 'pixels'),\n",
    "                                                #skipMasked = True)\n",
    "    # save files\n",
    "    #filename = 'PC_SD5010P_'+str(year)\n",
    "    #task = ee.batch.Export.image.toDrive(image=SD_DOY,description=filename,folder=\"curruspito_phenology\",\n",
    "                                         #scale=5565.974539663679,fileFormat='GeoTIFF',skipEmptyTiles=True,\n",
    "                                          #crs = 'EPSG:4326',maxPixels = 1e13,region = Rectangle1)\n",
    "\n",
    "    #task.start()\n",
    "\n",
    "    #--- compute 25th percentile\n",
    "    difFrom25 = cumulativeDOI.map(perc_25)\n",
    "    DOY25 = difFrom25.qualityMosaic('quality')\n",
    "    DOY25 = DOY25.updateMask(DOY25.select('mean').gt(0))\n",
    "    DOY25 = DOY25.updateMask(count_valid.gte(30))\n",
    "    for polygon in polygons:\n",
    "        print('DOY25 Year '+str(year)+' Polygon number '+str(polygon))\n",
    "        # subset polygon\n",
    "        tmp_poly = worldgrid.filterMetadata('polyID', 'equals', polygon).first().geometry()\n",
    "        # assetname\n",
    "        assetname = 'DOY25_'+str(year)+'_'+str(polygon)\n",
    "            # export tile\n",
    "        task = ee.batch.Export.image.toAsset(image=DOY25,description=assetname,assetId = 'users/marcogirardello/phenology'+assetname,\n",
    "                                     scale=463.3127165275,crs = 'EPSG:4326',maxPixels = 1e13,region = tmp_poly)\n",
    "        task.start()\n",
    "    \n",
    "    # calculate standard deviation\n",
    "    #SD_DOY = DOY25.select('DOY').reduceNeighborhood(reducer ='stdDev',kernel= ee.Kernel.square(6, 'pixels'),\n",
    "                                                #skipMasked = True)\n",
    "    # save files\n",
    "    #filename = 'PC_SD2510P_'+str(year)\n",
    "    #task = ee.batch.Export.image.toDrive(image=SD_DOY,description=filename,folder=\"curruspito_phenology\",\n",
    "    #                                     scale=5565.974539663679,fileFormat='GeoTIFF',skipEmptyTiles=True,\n",
    "    #                                      crs = 'EPSG:4326',maxPixels = 1e13,region = Rectangle1)\n",
    "\n",
    "    #task.start()\n",
    "    #--- compute 75th percentile\n",
    "    difFrom75 = cumulativeDOI.map(perc_75)\n",
    "    DOY75 = difFrom75.qualityMosaic('quality')\n",
    "    DOY75 = DOY75.updateMask(DOY75.select('mean').gt(0))\n",
    "    DOY75 = DOY75.updateMask(count_valid.gte(30))\n",
    "    for polygon in polygons:\n",
    "        print('DOY75 Year '+str(year)+' Polygon number '+str(polygon))\n",
    "        # subset polygon\n",
    "        tmp_poly = worldgrid.filterMetadata('polyID', 'equals', polygon).first().geometry()\n",
    "        # assetname\n",
    "        assetname = 'DOY75_'+str(year)+'_'+str(polygon)\n",
    "            # export tile\n",
    "        task = ee.batch.Export.image.toAsset(image=DOY75,description=assetname,assetId = 'users/marcogirardello/phenology'+assetname,\n",
    "                                     scale=463.3127165275,crs = 'EPSG:4326',maxPixels = 1e13,region = tmp_poly)\n",
    "        task.start()\n",
    "    \n",
    "    # calculate standard deviation\n",
    "    #SD_DOY = DOY75.select('DOY').reduceNeighborhood(reducer ='stdDev',kernel= ee.Kernel.square(6, 'pixels'),\n",
    "                                               # skipMasked = True)\n",
    "    # save files\n",
    "    #filename = 'PC_SD7510P_'+str(year)\n",
    "    #task = ee.batch.Export.image.toDrive(image=SD_DOY,description=filename,folder=\"curruspito_phenology\",\n",
    "    #                                     scale=5565.974539663679,fileFormat='GeoTIFF',skipEmptyTiles=True,\n",
    "    #                                      crs = 'EPSG:4326',maxPixels = 1e13,region = Rectangle1)\n",
    "\n",
    "    #task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cancel active exports\n",
    "#!earthengine task list  > info\n",
    "#!cat info | grep READY | awk '{print $1}' > tmp\n",
    "#! head tmp\n",
    "with open('tmp') as f:\n",
    "    lines = [line.rstrip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PX5W262AV2PNI4GRHEYRLDFO'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for line in lines:\n",
    "#    !earthengine task cancel TASK_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#line = lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running command using Cloud API.  Set --no-use_cloud_api to go back to using the API\n",
      "\n",
      "Unknown task id \"line\"\n"
     ]
    }
   ],
   "source": [
    "#!earthengine task cancel line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentiles calculated using the 10% NDVI rule for the Southern Hemisphere.\n",
    "##### In this version there is a time shift of 6 months for the Southern Hemisphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "south = ee.Geometry.Polygon(\n",
    "        [[[-178.2918491139962, 0.9228849968953224],\n",
    "          [-178.2918491139962, -61.42493117272831],\n",
    "          [179.98940088600375, -61.42493117272831],\n",
    "          [179.98940088600375, 0.9228849968953224]]], None, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through years\n",
    "years = list(range(2001, 2019+1))\n",
    "\n",
    "for year in years:\n",
    "    #print(year)\n",
    "    # year + 1\n",
    "    yearp1 = ee.Number(year).add(1)\n",
    "    # start and end date for a given year\n",
    "    start_date = ee.Date.fromYMD(year,7,1)\n",
    "    end_date = ee.Date.fromYMD(yearp1,6,30)\n",
    "    # filter dataset for a given year\n",
    "    MOD09ndviY = MOD09ndvi.filterDate(start_date, end_date)\n",
    "    # filter according to 10% rule\n",
    "    MaxNDVI_10 = MOD09ndviY.max().divide(10)\n",
    "    MOD09ndviY = MOD09ndviY.map(ndvi_filter10)\n",
    "    # value for the temporal smoothing bandwidth (21 days)\n",
    "    bw = 21\n",
    "    # This field contains UNIX time in milliseconds\n",
    "    timeField = 'system:time_start'\n",
    "    # sort collection by date\n",
    "    filteredMODIS = MOD09ndviY.sort('system:time_start')\n",
    "    # Smoothing\n",
    "    join = ee.Join.saveAll(matchesKey = 'images')\n",
    "    diffFilter = ee.Filter.maxDifference(difference =1000 * 60 * 60 * 24 * bw, \n",
    "                                     leftField = timeField,rightField = timeField)\n",
    "    threeNeighborJoin = join.apply(primary = filteredMODIS,secondary = filteredMODIS,condition = diffFilter)\n",
    "    # get smoothed collection\n",
    "    smoothed = ee.ImageCollection(threeNeighborJoin.map(smooth_func))\n",
    "    # mask smoothed dataset\n",
    "    smoothed_masked = smoothed.map(mask_smt)\n",
    "    # count valid images\n",
    "    count_valid = smoothed_masked.select('NDVI').count()\n",
    "    # unmask smoothed dataset\n",
    "    smoothed = smoothed.map(unmask_img)\n",
    "    # select mean band\n",
    "    smoothed = smoothed.select('mean')\n",
    "    # Define reference conditions from the first  year of data.\n",
    "    # Sort chronologically in descending order.\n",
    "    reference = smoothed.sort('system:time_start', True)\n",
    "    # Get the timestamp from the most recent image in the reference collection.\n",
    "    time0 = reference.first().get('system:time_start')\n",
    "    # Use imageCollection.iterate() to make a collection of cumulative NDVI over time.\n",
    "    # Rename the first band 'NDVI'.\n",
    "    first = ee.List([ee.Image(0).set('system:time_start', time0).select([0], ['mean']).toFloat()])\n",
    "    # cumulate NDVI\n",
    "    cumulative = ee.ImageCollection(ee.List(reference.iterate(accumulate, first)))\n",
    "    # add day of the year\n",
    "    cumulativeDOI = cumulative.map(addDOY)\n",
    "    # sum NDVI\n",
    "    Sum_NDVI = smoothed.sum()\n",
    "    #--- compute 50th percentile\n",
    "    difFrom50 = cumulativeDOI.map(perc_50)\n",
    "    DOY50 = difFrom50.qualityMosaic('quality')\n",
    "    DOY50 = DOY50.updateMask(DOY50.select('mean').gt(0))\n",
    "    DOY50 = DOY50.updateMask(count_valid.gte(30))\n",
    "    # calculate standard deviation\n",
    "    SD_DOY = DOY50.select('DOY').reduceNeighborhood(reducer ='stdDev',kernel= ee.Kernel.square(6, 'pixels'),\n",
    "                                                skipMasked = True)\n",
    "    # save files\n",
    "    filename = 'PC_SD5010PSOUTH_'+str(year)\n",
    "    task = ee.batch.Export.image.toDrive(image=SD_DOY,description=filename,folder=\"curruspito_phenology\",\n",
    "                                         scale=5565.974539663679,fileFormat='GeoTIFF',skipEmptyTiles=True,\n",
    "                                          crs = 'EPSG:4326',maxPixels = 1e13,region = south)\n",
    "\n",
    "    task.start()\n",
    "    #--- compute 25th percentile\n",
    "    difFrom25 = cumulativeDOI.map(perc_25)\n",
    "    DOY25 = difFrom25.qualityMosaic('quality')\n",
    "    DOY25 = DOY25.updateMask(DOY25.select('mean').gt(0))\n",
    "    DOY25 = DOY25.updateMask(count_valid.gte(30))\n",
    "    # calculate standard deviation\n",
    "    SD_DOY = DOY25.select('DOY').reduceNeighborhood(reducer ='stdDev',kernel= ee.Kernel.square(6, 'pixels'),\n",
    "                                                skipMasked = True)\n",
    "    # save files\n",
    "    filename = 'PC_SD2510PSOUTH_'+str(year)\n",
    "    task = ee.batch.Export.image.toDrive(image=SD_DOY,description=filename,folder=\"curruspito_phenology\",\n",
    "                                         scale=5565.974539663679,fileFormat='GeoTIFF',skipEmptyTiles=True,\n",
    "                                          crs = 'EPSG:4326',maxPixels = 1e13,region = south)\n",
    "\n",
    "    task.start()\n",
    "    #--- compute 75th percentile\n",
    "    difFrom75 = cumulativeDOI.map(perc_75)\n",
    "    DOY75 = difFrom75.qualityMosaic('quality')\n",
    "    DOY75 = DOY75.updateMask(DOY75.select('mean').gt(0))\n",
    "    DOY75 = DOY75.updateMask(count_valid.gte(30))\n",
    "    # calculate standard deviation\n",
    "    SD_DOY = DOY75.select('DOY').reduceNeighborhood(reducer ='stdDev',kernel= ee.Kernel.square(6, 'pixels'),\n",
    "                                                skipMasked = True)\n",
    "    # save files\n",
    "    filename = 'PC_SD7510PSOUTH_'+str(year)\n",
    "    task = ee.batch.Export.image.toDrive(image=SD_DOY,description=filename,folder=\"curruspito_phenology\",\n",
    "                                         scale=5565.974539663679,fileFormat='GeoTIFF',skipEmptyTiles=True,\n",
    "                                          crs = 'EPSG:4326',maxPixels = 1e13,region = south)\n",
    "\n",
    "    task.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
